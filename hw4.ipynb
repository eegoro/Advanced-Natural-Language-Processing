{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Soft deadline: `30.03.2022 23:59`","metadata":{"id":"nXpkXz1QJmhJ"}},{"cell_type":"markdown","source":"In this homework you will understand the fine-tuning procedure and get acquainted with Huggingface Datasets library","metadata":{"id":"yxy7euTpCbGp"}},{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/datasets#egg=datasets","metadata":{"id":"fFBIWkey0DJ1","outputId":"fe5394a7-de5f-4b40-e973-a7d5e51aa3d6","execution":{"iopub.status.busy":"2022-03-30T01:22:30.865829Z","iopub.execute_input":"2022-03-30T01:22:30.866234Z","iopub.status.idle":"2022-03-30T01:22:53.633242Z","shell.execute_reply.started":"2022-03-30T01:22:30.866139Z","shell.execute_reply":"2022-03-30T01:22:53.632321Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting datasets\n  Cloning https://github.com/huggingface/datasets to /tmp/pip-install-c1ur2ha8/datasets_5028cd2b25794f1082660f92677724f9\n  Running command git clone --filter=blob:none -q https://github.com/huggingface/datasets /tmp/pip-install-c1ur2ha8/datasets_5028cd2b25794f1082660f92677724f9\n  Resolved https://github.com/huggingface/datasets to commit d7a3a76c12798b90de9e7fa41fd7007cd4d6ca27\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.20.3)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.26.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.62.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.12.2)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\nRequirement already satisfied: huggingface_hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.4.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: importlib_metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.11.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from huggingface_hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface_hub<1.0.0,>=0.1.0->datasets) (3.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub<1.0.0,>=0.1.0->datasets) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (3.0.6)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.7)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.0.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (5.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.2.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib_metadata->datasets) (3.6.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2021.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\nBuilding wheels for collected packages: datasets\n  Building wheel for datasets (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for datasets: filename=datasets-2.0.1.dev0-py3-none-any.whl size=326571 sha256=63aa5a5b41feea73dd9de7d2e3a0f49375e77e033e763617dd9219cd4a7e4a8a\n  Stored in directory: /tmp/pip-ephem-wheel-cache-8p00_m_0/wheels/cb/6a/f6/1b735389402c6a7cfd6af75fae91ac8ac34d900c197df34b67\nSuccessfully built datasets\nInstalling collected packages: datasets\n  Attempting uninstall: datasets\n    Found existing installation: datasets 1.18.4\n    Uninstalling datasets-1.18.4:\n      Successfully uninstalled datasets-1.18.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nallennlp 2.9.1 requires datasets<2.0,>=1.2.1, but you have datasets 2.0.1.dev0 which is incompatible.\u001b[0m\nSuccessfully installed datasets-2.0.1.dev0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install datasets \n! pip install transformers","metadata":{"id":"_1MXcMymXeCx","outputId":"8f082943-9f46-4ff6-f96d-ff6d7a49e30b","execution":{"iopub.status.busy":"2022-03-30T01:22:53.635566Z","iopub.execute_input":"2022-03-30T01:22:53.635832Z","iopub.status.idle":"2022-03-30T01:23:08.562112Z","shell.execute_reply.started":"2022-03-30T01:22:53.635797Z","shell.execute_reply":"2022-03-30T01:23:08.561303Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.0.1.dev0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.11.3)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.4.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.12.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.20.3)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (21.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.26.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.62.3)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.2.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (3.0.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.1)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.0.9)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.7)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.1)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (5.2.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.6.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2021.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.16.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.6.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.3)\nRequirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.11.6)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.4.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.26.0)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.49)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.20.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.6)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.6.0)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.7)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"For our goals we will use [Datasets](https://huggingface.co/docs/datasets/) library and take `yahoo_answers_topics` dataset - the task of this dataset is to divide documents on 10 topic categories. More detiled information can be found on the dataset [page](https://huggingface.co/datasets/viewer/).\n","metadata":{"id":"FykUK-TFXf-2"}},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"id":"ebsFAQsgXNB0","execution":{"iopub.status.busy":"2022-03-30T01:23:08.565533Z","iopub.execute_input":"2022-03-30T01:23:08.565792Z","iopub.status.idle":"2022-03-30T01:23:10.573112Z","shell.execute_reply.started":"2022-03-30T01:23:08.565766Z","shell.execute_reply":"2022-03-30T01:23:10.572342Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import datasets","metadata":{"id":"q5oUxS9r0iQt","execution":{"iopub.status.busy":"2022-03-30T01:23:10.574731Z","iopub.execute_input":"2022-03-30T01:23:10.575444Z","iopub.status.idle":"2022-03-30T01:23:10.579696Z","shell.execute_reply.started":"2022-03-30T01:23:10.575376Z","shell.execute_reply":"2022-03-30T01:23:10.578963Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"dataset = load_dataset('yahoo_answers_topics') # the result is a dataset dictionary of train and test splits in this case","metadata":{"id":"UbzxZi42XOUG","outputId":"cd9c5338-792a-45ab-8b99-77cd26ea7a0d","execution":{"iopub.status.busy":"2022-03-30T01:23:10.582668Z","iopub.execute_input":"2022-03-30T01:23:10.583256Z","iopub.status.idle":"2022-03-30T01:25:14.133037Z","shell.execute_reply.started":"2022-03-30T01:23:10.583217Z","shell.execute_reply":"2022-03-30T01:25:14.132291Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"075a32ebd288473d9281b13b5574c2e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/847 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30529dcb6cab4349a21088645bc7103c"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset yahoo_answers_topics/yahoo_answers_topics (download: 304.68 MiB, generated: 756.38 MiB, post-processed: Unknown size, total: 1.04 GiB) to /root/.cache/huggingface/datasets/yahoo_answers_topics/yahoo_answers_topics/1.0.0/0edb353eefe79d9245d7bd7cac5ae6af19530439da520d6dde1c206ee38f4439...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/319M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8763918ab1bc4083bcbcce9da6a86e25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1400000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/60000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset yahoo_answers_topics downloaded and prepared to /root/.cache/huggingface/datasets/yahoo_answers_topics/yahoo_answers_topics/1.0.0/0edb353eefe79d9245d7bd7cac5ae6af19530439da520d6dde1c206ee38f4439. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc96862a44f64602ba403ebacba72e77"}},"metadata":{}}]},{"cell_type":"code","source":"N = 10000\nfrac = 0.2\ndataset['train'] = dataset['train'].shuffle(seed=42).select(indices=range(0,N))\ndataset['test'] = dataset['test'].shuffle(seed=42).select(indices=range(0,int(N*frac)))","metadata":{"id":"kCr8HzALCe5L","execution":{"iopub.status.busy":"2022-03-30T01:25:14.134549Z","iopub.execute_input":"2022-03-30T01:25:14.135081Z","iopub.status.idle":"2022-03-30T01:25:14.667084Z","shell.execute_reply.started":"2022-03-30T01:25:14.135039Z","shell.execute_reply":"2022-03-30T01:25:14.666375Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Fine-tuning the model** (20 points)","metadata":{"id":"4U4YUOB5W8uG"}},{"cell_type":"code","source":"from transformers import (ElectraTokenizer, ElectraForSequenceClassification,\n                          get_scheduler, InputFeatures,pipeline,\n                          ElectraForMaskedLM, ElectraModel)\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom datasets import load_metric","metadata":{"id":"ZDYIq9l7CYBR","execution":{"iopub.status.busy":"2022-03-30T01:25:14.670628Z","iopub.execute_input":"2022-03-30T01:25:14.672358Z","iopub.status.idle":"2022-03-30T01:25:22.508373Z","shell.execute_reply.started":"2022-03-30T01:25:14.672326Z","shell.execute_reply":"2022-03-30T01:25:22.507596Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Fine-tuning procedure on the end task consists of adding additional layers on the top of the pre-trained model. The resulting model can be tuned fully (passing gradients through the all model) or partially.","metadata":{"id":"ElZ6k36rb0VG"}},{"cell_type":"markdown","source":"**Task**: \n- load tokenizer and model\n- look at the predictions of the model as-is before any fine-tuning\n\n\n```\n- Why don't you ask [MASK]?\n- What is [MASK]\n- Let's talk about [MASK] physics\n```\n\n- convert `best_answer` to the input tokens (supporting function for dataset is provided below) \n\n```\ndef tokenize_function(examples):\n    return tokenizer(examples[\"best_answer\"], padding=\"max_length\", truncation=True)\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\n```\n\n- define optimizer, sheduler (optional)\n- fine-tune the model (write the training loop), plot the loss changes and measure results in terms of weighted F1 score\n- get the masked word prediction (sample sentences above) on the fine-tuned model, why the results as they are and what should be done in order to change that (write down your answer)\n- Tune the training hyperparameters (and write down your results).\n\n**Tips**:\n- The easiest way to get predictions is to use transformers `pipeline` function \n- Do not forget to set `num_labels` parameter, when initializing the model\n- To convert data to batches use `DataLoader`\n- Even the `small` version of Electra can be long to train, so you can take data sample (>= 5000 and set seed for reproducibility)\n- You may want to try freezing (do not update the pretrained model weights) all the layers exept the ones for classification, in that case use:\n\n\n```\nfor param in model.electra.parameters():\n      param.requires_grad = False\n```\n","metadata":{"id":"pNEmksaPb3Uu"}},{"cell_type":"code","source":"MODEL_NAME = \"google/electra-small-generator\"\nTOKENIZER_NAME = \"google/electra-small-generator\"\nBATCH_SIZE = 512\nEPOCHS = 30\nLEARNING_RATE = 10e-4\nNUM_WORKERS = 2\nPATIENCE = 5 # amount of epochs without loss change to stop training\nFREEZE = True","metadata":{"id":"8yqAAFqZcwbu","execution":{"iopub.status.busy":"2022-03-30T01:25:22.509571Z","iopub.execute_input":"2022-03-30T01:25:22.510468Z","iopub.status.idle":"2022-03-30T01:25:22.514608Z","shell.execute_reply.started":"2022-03-30T01:25:22.510434Z","shell.execute_reply":"2022-03-30T01:25:22.513860Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"tokenizer = ElectraTokenizer.from_pretrained(TOKENIZER_NAME)\nmodel = ElectraForSequenceClassification.from_pretrained(MODEL_NAME, num_labels = 10)","metadata":{"id":"WNsdKdPm0DJ7","outputId":"29311f41-8684-4f96-8864-6c4484e2cdfa","execution":{"iopub.status.busy":"2022-03-30T01:25:22.515847Z","iopub.execute_input":"2022-03-30T01:25:22.516250Z","iopub.status.idle":"2022-03-30T01:25:25.797739Z","shell.execute_reply.started":"2022-03-30T01:25:22.516212Z","shell.execute_reply":"2022-03-30T01:25:25.797005Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb3d30bde712496186251511ab4ab343"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a73c4a1ee2f3440fa222a41118d1d1c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f85ac5aad5f343f0b638e1d313dcfe5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/662 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df8dee104e8146dd9f149db5179ae7e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/51.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8535f5cea4d464faaffc18b3b07cdcf"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at google/electra-small-generator were not used when initializing ElectraForSequenceClassification: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_predictions.LayerNorm.bias', 'generator_predictions.dense.bias', 'generator_predictions.LayerNorm.weight', 'generator_lm_head.weight']\n- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-generator and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"pipe = pipeline(model=MODEL_NAME)\npipe(\"Why don't you ask [MASK]?\")","metadata":{"id":"XYCmmreF8Nn_","outputId":"7cc7452c-aba3-46d8-a785-bdefe00c1d7c","execution":{"iopub.status.busy":"2022-03-30T01:25:25.799024Z","iopub.execute_input":"2022-03-30T01:25:25.799352Z","iopub.status.idle":"2022-03-30T01:25:28.560147Z","shell.execute_reply.started":"2022-03-30T01:25:25.799311Z","shell.execute_reply":"2022-03-30T01:25:28.559420Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.02k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56dc956a0dcc437f8ecaa9901bbfc72b"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.5343002080917358,\n  'token': 2033,\n  'token_str': 'me',\n  'sequence': \"why don't you ask me?\"},\n {'score': 0.0819597840309143,\n  'token': 3980,\n  'token_str': 'questions',\n  'sequence': \"why don't you ask questions?\"},\n {'score': 0.043953415006399155,\n  'token': 2068,\n  'token_str': 'them',\n  'sequence': \"why don't you ask them?\"},\n {'score': 0.04017249867320061,\n  'token': 2339,\n  'token_str': 'why',\n  'sequence': \"why don't you ask why?\"},\n {'score': 0.030024176463484764,\n  'token': 4426,\n  'token_str': 'yourself',\n  'sequence': \"why don't you ask yourself?\"}]"},"metadata":{}}]},{"cell_type":"code","source":"pipe(\"What is [MASK]?\")","metadata":{"id":"TI83mNg58rjI","outputId":"f7d614ec-a338-4933-8101-a2ddcfa2df3f","execution":{"iopub.status.busy":"2022-03-30T01:25:28.561707Z","iopub.execute_input":"2022-03-30T01:25:28.561972Z","iopub.status.idle":"2022-03-30T01:25:28.590621Z","shell.execute_reply.started":"2022-03-30T01:25:28.561935Z","shell.execute_reply":"2022-03-30T01:25:28.589877Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.4963121712207794,\n  'token': 2009,\n  'token_str': 'it',\n  'sequence': 'what is it?'},\n {'score': 0.2050580382347107,\n  'token': 2023,\n  'token_str': 'this',\n  'sequence': 'what is this?'},\n {'score': 0.12763574719429016,\n  'token': 2008,\n  'token_str': 'that',\n  'sequence': 'what is that?'},\n {'score': 0.015324683859944344,\n  'token': 3308,\n  'token_str': 'wrong',\n  'sequence': 'what is wrong?'},\n {'score': 0.015023304149508476,\n  'token': 2054,\n  'token_str': 'what',\n  'sequence': 'what is what?'}]"},"metadata":{}}]},{"cell_type":"code","source":"pipe(\"Let's talk about [MASK] physics\")","metadata":{"id":"xs9L7nPW83TR","outputId":"395cfb73-ac1e-4b61-a15b-f3640c4359b8","execution":{"iopub.status.busy":"2022-03-30T01:25:28.591865Z","iopub.execute_input":"2022-03-30T01:25:28.592806Z","iopub.status.idle":"2022-03-30T01:25:28.849052Z","shell.execute_reply.started":"2022-03-30T01:25:28.592762Z","shell.execute_reply":"2022-03-30T01:25:28.848320Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.24027419090270996,\n  'token': 8559,\n  'token_str': 'quantum',\n  'sequence': \"let's talk about quantum physics\"},\n {'score': 0.2125832438468933,\n  'token': 9373,\n  'token_str': 'theoretical',\n  'sequence': \"let's talk about theoretical physics\"},\n {'score': 0.05639351159334183,\n  'token': 10811,\n  'token_str': 'particle',\n  'sequence': \"let's talk about particle physics\"},\n {'score': 0.03320807218551636,\n  'token': 2613,\n  'token_str': 'real',\n  'sequence': \"let's talk about real physics\"},\n {'score': 0.022627977654337883,\n  'token': 8045,\n  'token_str': 'mathematical',\n  'sequence': \"let's talk about mathematical physics\"}]"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(examples[\"best_answer\"], padding=\"max_length\", truncation=True)\n\ncolumns = list(dataset['train'].features.keys())\ncolumns.remove('topic')\ntokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=columns)\ntokenized_datasets = tokenized_datasets.rename_column(\"topic\", \"labels\")\ntokenized_datasets.set_format(\"torch\")","metadata":{"id":"AXlY_IIN5TcG","outputId":"72e0167a-234d-4ddf-9e45-66c24a0d0f61","execution":{"iopub.status.busy":"2022-03-30T01:25:28.850395Z","iopub.execute_input":"2022-03-30T01:25:28.850823Z","iopub.status.idle":"2022-03-30T01:25:59.298022Z","shell.execute_reply.started":"2022-03-30T01:25:28.850781Z","shell.execute_reply":"2022-03-30T01:25:59.297228Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca0d4b23f1f441be98ff6d3526bcd70d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f22bbc391b2415dbf4248d04887401a"}},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\ntrainloader = DataLoader(tokenized_datasets['train'],shuffle=True,  \n                         batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\ntestloader = DataLoader(tokenized_datasets['test'], batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)","metadata":{"id":"N-nT8-NO7vQp","execution":{"iopub.status.busy":"2022-03-30T01:25:59.301696Z","iopub.execute_input":"2022-03-30T01:25:59.301921Z","iopub.status.idle":"2022-03-30T01:25:59.309008Z","shell.execute_reply.started":"2022-03-30T01:25:59.301893Z","shell.execute_reply":"2022-03-30T01:25:59.306306Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"if FREEZE:\n    for param in model.electra.parameters():\n          param.requires_grad = False","metadata":{"id":"y52sQfuAJmCe","execution":{"iopub.status.busy":"2022-03-30T01:25:59.310488Z","iopub.execute_input":"2022-03-30T01:25:59.310798Z","iopub.status.idle":"2022-03-30T01:25:59.535595Z","shell.execute_reply.started":"2022-03-30T01:25:59.310760Z","shell.execute_reply":"2022-03-30T01:25:59.534731Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)","metadata":{"id":"xOXvxwKqLPGU","execution":{"iopub.status.busy":"2022-03-30T01:25:59.537328Z","iopub.execute_input":"2022-03-30T01:25:59.537665Z","iopub.status.idle":"2022-03-30T01:25:59.547050Z","shell.execute_reply.started":"2022-03-30T01:25:59.537624Z","shell.execute_reply":"2022-03-30T01:25:59.546260Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel.to(device)\nprint('')","metadata":{"id":"0CGw1bZbfMhN","outputId":"3878e08d-a835-452c-cca3-e85fb08b5a96","execution":{"iopub.status.busy":"2022-03-30T01:25:59.548713Z","iopub.execute_input":"2022-03-30T01:25:59.549024Z","iopub.status.idle":"2022-03-30T01:26:04.254486Z","shell.execute_reply.started":"2022-03-30T01:25:59.548968Z","shell.execute_reply":"2022-03-30T01:26:04.253744Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm.auto import tqdm\nimport numpy as np\nfrom sklearn.metrics import f1_score\n\ndef compute_F1(true,pred):\n    pred = pred.argmax(dim=(-1))\n    return f1_score(true.cpu(), pred.cpu(), average='weighted')\n\n# Set seed for reproducibility\nnp.random.seed(2021)\ntorch.manual_seed(2021)\n\nprogress_bar = tqdm(range(len(trainloader)*EPOCHS))\n\n\nmetrics = {}\nfor m in ['train_loss','val_loss','train_f1','val_f1']:\n    metrics[m] = []\n\nfor epoch in range(EPOCHS):\n    running_loss = []\n    running_f1 = []\n    for batch in trainloader:\n        model.train()\n\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        running_loss.append(float(loss))\n        running_f1.append(compute_F1(batch['labels'],outputs.logits))\n\n        progress_bar.update(1)\n        progress_bar.set_description(\n            f\"Epoch: {epoch+1}/{EPOCHS}, loss: {np.mean(running_loss):.4f}, f1 score: {np.mean(running_f1):.4f}\"\n            )\n    \n    metrics['train_loss'].append(np.mean(running_loss))\n    metrics['train_f1'].append(np.mean(running_f1))\n\n    running_loss = []\n    running_f1 = []\n    for batch in testloader:\n        model.eval()\n        with torch.no_grad():\n            batch = {k: v.to(device) for k, v in batch.items()}\n            outputs = model(**batch)\n            loss = outputs.loss\n        running_loss.append(float(loss))\n        running_f1.append(compute_F1(batch['labels'],outputs.logits))\n    metrics['val_loss'].append(np.mean(running_loss))\n    metrics['val_f1'].append(np.mean(running_f1))\n    print(f'Validation loss: {np.mean(running_loss):.4f}, f1 score: {np.mean(running_f1):.4f}')\n\n    if epoch >= PATIENCE and np.std(metrics['val_loss'][-PATIENCE:]) < 1e-3:\n      print('Early stopping condition is true')\n      break\n    torch.cuda.empty_cache()\n\nprint('Training finished') ","metadata":{"id":"b9H278r1fhor","outputId":"05ab3e62-9e0a-404e-a833-3b5968d86fff","execution":{"iopub.status.busy":"2022-03-30T01:26:04.255868Z","iopub.execute_input":"2022-03-30T01:26:04.256277Z","iopub.status.idle":"2022-03-30T01:49:27.013696Z","shell.execute_reply.started":"2022-03-30T01:26:04.256239Z","shell.execute_reply":"2022-03-30T01:49:27.012808Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/600 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"845e12e45e1440dfa89c2e24fa48b033"}},"metadata":{}},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 2.2344, f1 score: 0.2264\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 2.0806, f1 score: 0.3220\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.9326, f1 score: 0.3571\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.8461, f1 score: 0.3829\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.7832, f1 score: 0.4455\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.7578, f1 score: 0.3973\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.7026, f1 score: 0.4380\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.6985, f1 score: 0.4372\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.6736, f1 score: 0.4524\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.6613, f1 score: 0.4628\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.6372, f1 score: 0.4612\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.6321, f1 score: 0.4881\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.6270, f1 score: 0.4730\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.6297, f1 score: 0.4723\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.6241, f1 score: 0.4886\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.6048, f1 score: 0.4645\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.6104, f1 score: 0.4822\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.6004, f1 score: 0.4676\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.6031, f1 score: 0.4880\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.6134, f1 score: 0.4684\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.5986, f1 score: 0.4863\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.5974, f1 score: 0.4881\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.6030, f1 score: 0.4719\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.5805, f1 score: 0.4932\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.5817, f1 score: 0.4986\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.5846, f1 score: 0.4698\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.5737, f1 score: 0.4903\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.5764, f1 score: 0.4795\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.5762, f1 score: 0.4943\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nValidation loss: 1.5811, f1 score: 0.4897\nTraining finished\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10,5))\nfor key in metrics.keys():\n    if 'f1' in key:\n        plt.subplot(122)\n        plt.plot(np.arange(EPOCHS)+1, metrics[key], 'o-',label=key)\n    else:\n        plt.subplot(121)\n        plt.plot(np.arange(EPOCHS)+1, metrics[key], 'o-',label=key)\n    plt.grid(True)\n    plt.xlabel('epochs')\n    plt.legend()\n","metadata":{"id":"JI3bDtRLIZL6","execution":{"iopub.status.busy":"2022-03-30T01:49:27.015407Z","iopub.execute_input":"2022-03-30T01:49:27.016295Z","iopub.status.idle":"2022-03-30T01:49:27.433080Z","shell.execute_reply.started":"2022-03-30T01:49:27.016254Z","shell.execute_reply":"2022-03-30T01:49:27.432398Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 720x360 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAlMAAAE9CAYAAAAvV+dfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABxPUlEQVR4nO3deXiU5fXw8e/JHkhIIECAhCUssiMo4IJKlCqIC9QFXKvWvtZWq9VKi/5atLjR2mpr61K1VmvdKCJiQVGB4AayBcK+IyQogYRskD33+8czk0ySmWSSmcksOZ/r4srMs83JQIaT+zn3ucUYg1JKKaWUap0wfweglFJKKRXMNJlSSimllPKAJlNKKaWUUh7QZEoppZRSygOaTCmllFJKeUCTKaWUUkopD0T464W7du1q+vXrV/v85MmTdOzY0V/hNCuQ4wvk2EDj81Qgx9fS2DZs2HDcGNPNhyG1GcfPsED+OwKNzxOBHBtofJ5qSXxNfn4ZY/zy58wzzzSOVq5caQJZIMcXyLEZo/F5KpDja2lswHrjp88cb/9x/AwL5L8jYzQ+TwRybMZofJ5qSXxNfX41e5tPRHqLyEoR2S4i20TkXifHTBORLBHZJCLrReQ8t9I8pZRSSqkg585tvirgV8aYjSISD2wQkU+NMdsdjlkOLDbGGBEZBcwHhvggXqWUUkqpgNLsyJQx5jtjzEbb42JgB5DS4JgS2xAYQEdA16hRSimlVLvQogJ0EekHjAG+cbLvh8CTQHfgMm8Ep1RbqqysJDs7m7KyMn+HUk9CQgI7duzwdxhOuYotJiaG1NRUIiMj/RCVUkq1LbeTKRGJA94DfmmMKWq43xjzPvC+iFwAPAr8wMk17gDuAEhOTiYjI6N2X0lJSb3ngSaQ4wvk2CB44ouLiyM5OZmUlBRExN9h1aquriY8PNzfYTjlLDZjDIWFhWzevJmSkhI/RaaUUm3HrWRKRCKxEqk3jTELmzrWGPO5iPQXka7GmOMN9r0EvAQwduxYk56eXrsvIyMDx+eBJpDjC+TYIHji27FjB6mpqQGVSAEUFxcTHx/v7zCcchVbfHw8JSUljB071g9RKaVU23JnNp8A/wR2GGOednHMQNtxiMgZQDSQ581AlWoLgZZIBSt/vI8iMkVEdonIXhGZ7WT/rSJyzDbreJOI/MRh3y0issf255a2jVwpFezcGZmaANwMbBGRTbZtDwF9AIwxLwJXAz8SkUqgFJjpUJDukUWZOTy1bBdHCkrplRjLrMmDmT4mpfkTlVLthoiEA88BFwPZwDoRWdxg1jHAu8aYuxuc2wV4GBiLNXlmg+3cE20QulKhKWs+LJ/LxMJsyEyFSXNg1Ax/R+Uz7szm+9IYI8aYUcaY0bY/S40xL9oSKYwxfzDGDLftO8cY86U3gluUmcODC7eQU1CKAXIKSnlw4RYWZeZ44/JKBZSCggKef/75Fp83depUCgoKWnzerbfeyoIFC1p8XoAaD+w1xuw3xlQA7wDT3Dx3MvCpMSbflkB9CkzxUZxKhb6s+fDhPVB4GMFA4WHredZ8f0fmM35bTsYdTy3bRWlldb1tpZXVPLVsl45OKb/z9qipPZn6+c9/Xm97VVVVk+ctXbq01a8ZQlKAww7Ps4GznBx3tW2SzG7gPmPMYRfnOv2LdDWJJlgmWQSqQI4vkGODwIzv7NUPEVNZWn9jZSllSx5iTX53/wTlgrfev4BOpo4UlLZou1JtxT5qak/27aOmQKsTqtmzZ7Nv3z5Gjx5NZGQkMTExdO7cme3bt7N3716mT5/O4cOHKSsr49577+WOO+4AoF+/fqxfv56SkhIuvfRSzjvvPL7++mtSUlL44IMPiI2Nbfa1ly9fzgMPPEBVVRXjxo3jhRdeIDo6mtmzZ7N48WIiIiK45JJL+NOf/sR///tffv/73xMeHk5cXBxfffVVq75fP/gQeNsYUy4iPwVeBy5qyQVcTaIJlkkWgSqQ4wvk2CAA4ysrhIxjTnfFlB9vu1httxkpzIYE17cZvfX+BXQy1SsxlhwniVOvxOb/c1DKE7//cBvbjzTqAFIr81ABFdU19baVVlbz6wVZvL32kNNzhvXqxMNXDHd5zXnz5rF161Y2bdpERkYGl112GVu3bqVr164AvPrqq3Tp0oXS0lLGjRvH1VdfTVJSUr1r7Nmzh7fffpuXX36ZGTNm8N5773HTTTc1+b2WlZVx6623snz5ck477TR+9KMf8cILL3DzzTfz/vvvs3PnTkSk9lbi3LlzWbZsGSkpKRw+fLjJa7ehHKC3w/NU27ZaxhjHSTGvAH90ODe9wbkZXo9QqVDSMFkZdzsUHILN77o+JyG17WL78B6wj47ZbzOCz+q2mq2Z8qdZkwcTG1m/h01sZDizJg/2U0RKWRomUs1tb43x48eTlpZW+/zZZ5/l9NNP5+yzz+bw4cPs2bOn0TlpaWmMHj0agDPPPJODBw82+zq7du0iLS2N0047DYBbbrmFzz//nISEBGJiYrj99ttZuHAhHTp0AGDChAnceuutvPzyy1RXVzd16ba0DhgkImkiEgVcByx2PEBEejo8vRJrNQeAZcAlItJZRDoDl9i2KaWccaiJwl4T9dkjsOF1GP5DuPC3ENlg0CMy1hodagvL59YlUnaVpdZ2HwnokSn77ZKHF2+jsLSS5E7RPHjpUK2XUj7X1AgSwIR5K5yOmqYkxvLuT8/xSgwdO3asfZyRkcFnn33G6tWr6dChA+np6U47tUdHR9c+Dg8Pp7S09bfEIyIiWLt2LcuXL2fBggX8/e9/Z8WKFbz44ot88803LFmyhIkTJ7Jx48ZGI2RtzRhTJSJ3YyVB4cCrxphtIjIXa6X3xcA9InIl1nqj+cCttnPzReRRrIQMYK4xJr/NvwmlgoWzZAUgPhmmP2c97twXls/FFB5GAC76bctGhdy8TedUYbaL7Yeh4iREdfT6bMOATqbASqj6d+vIlX//ijmXD+eyUT2bP0kpH5s1eXC9minwfNQ0Pj6e4uJip/sKCwvp3LkzHTp0YOfOnaxZs6bVr9PQ4MGDOXjwIHv37mXgwIG88cYbTJw4kZKSEk6dOsXUqVOZMGEC/fv3B2Dfvn2cddZZnHXWWfzvf//j8OHDfk+mAIwxS4GlDbbNcXj8IPCgi3NfBV71aYDK+zz5D9fNa/ttar8vvzdPr+8qWSn6ru7xqBkwagarl73Hud/8FApaUBLg6W266Hgod1Gm8afTIHkkHNkI1eVWoueF24ABn0wBDO4RT2S4kJVToMmUCgj20VFvzuZLSkpiwoQJjBgxgtjYWJKTk2v3TZkyhRdffJGhQ4cyePBgzj77bI+/B7uYmBj+9a9/ce2119YWoN95553k5+czbdo0ysrKMMbw9NNWz95Zs2axZ88ejDGcf/75nH766V6LRSm3+bIuxuHa3vrPtrWvT2tfv6lkydPrd+oFRU5aFDmpiaqIToIRV0Hmf+DChyAmofnrN3Wbrrn4Mt+0EikJB+NQhhAZC2ffBSVHrVho0ArT3eu7EBTJVHREOEN6dGJrTqG/Q1Gq1vQxKV6/5fzWW2853R4dHc1HH33kdJ+9Lqpr165s3bq1dvsDDzzQ5Gu99tprtY8nTZpEZmZmvf09e/Zk7dq1jc5buLBuRani4mLtGq/8w5P/cP157bZ4fWfJ0mJbjVPSIFj6gGfX7zakcTLVVE3U2T+DrHdh4xtw7t3Oj3Hk8jadi+12+1dZ33f/dBh1Hax83Hkymfmf1l2/CUGRTAGMTE3gw81HMMboh7dSSrV3rf0P19/XbovXd5aMVblRgO3O9Y9ug/0ZkDYR8ve7d5uw1xjocy588w84604Ibyb16JAEp4472d7F9Tm5O+Hdm61kcca/rRGw0dc7PzYh1VY872R7KwX0bD5HI1MSKC6r4tu8U/4ORamgctdddzF69Oh6f/71r3/5OyylPNOpl/Pt3ph+H++inKQl186aD8+MgEcSra8t6f7t6nXcff2mkqI7MqCTixH15q5vDCx5wEpUrn0N7tsKjxRYX5sb0Trn51B4CHb+r+njKk5Zr0ODQRMJg1N58MWfbfsdlOTCW9dCZAzcOL/5W4mT5nh9tmHwjEylWG/OlpxC+nXt2MzRSim75557zt8hKOV9KeMa32qScLjod55dt6qi8X+0YP1n7u5/tp7WJI2aYSUNrX39TilQ5CShSuhtjRL94JH68dmd84umr7tlARz6Gi7/S9OjRM4Mngqd+8Ga52H4dNfHffEnKM2D839lvY/2ka/0B2HfCmt07fheSDsfVj5h7Q+PsEqgbv8EEvs0H4v972D5XExhNuKFAv+gGZk6LTmeqIgwtmjdlFJKtW8Vp+DbL6xZWQm9AYGYRKvgOLfh2tYt9MlvIX8fjL8DEnpjEIjtDKYGoju5dw1P+hxVlcP2D6BDV+iUCo6vX9W4HYpT3ZzMKnYceRk1A654tu69i+sB4dGwZb71+s6UFVnvTa8xcMaP3IvDUVi4dYvv8DeQvcH5Mbk74atn4fQbrFgdR77G3AhXv2IlVZvfgg/uqutzVV0JIpC31/14Rs2A+7ayKn2ReyNrzX17Hp3dhqIiwhjasxNZ2QX+DkUppZQ/bfy3dctn6lN1/+H+5iCMvR2++ovrAuPmZM2Htf+Ac+6uvfaq9EXwwB7o0h9WPAo1bjTm9aTm6cu/WEnBVf+A+7dZ39us/dD3PFj22/rtB5zZ8xnsWw79L6pLlhJ6W8mTY8JgSyZ4pAAe2AVXvww56+Hj2c6v+/kfoeR7mPpnKzFqjTE3WQnpGiej5cbA/+6D6Di45FHn54tA+myITbKSS0fVFT5tytmcoEmmAEamdGJrThE1Nab5g5VSSoWeqgr4+m/Q5xzo69AgVwQu/QP0vxA+/CUc/LJl1/1+qzXjre8E6zaYo/BIuPD/4OhW2Ppe89dyVc/VqZnWPsf3Wre5RlwNA39Qtz0sDK58FqrLYcn9jWuG7E4eh0U/g25D4fq3WlbTNGwaTLgX1r/aOBnN3QlrXoAxN0PqmU1fpynR8dao1rZFjRPLTW9ZtxAvngsduzZ9nVIXPXXbaoKAE0GVTI1KSaSkvIqDeSf9HYpSSil/2PJfqx7ovPsb7wuPtAqju6TBuzdZSZc7ReClBTD/Zqtw+Zp/WddpaPhV1m3FlY9ZCZ0rxkBcd+f7ImKddw63n7fkPuuYyU823p80wErodi2Fbe87P/+Du6GswLod5qzuqzkXzbFm6f3vfjiSWXfdj2ZZXcMbJpmtMf4OwMDal+q2ncyzbiH2PhtGN72WKOB5gb4PBH4y5TAjYvqqyVwZ9qXWTanA4MlsHS+Ii4tzue/gwYOMGDGiDaNRqg3U1Fi38ZJHwqCLnR8Tmwg3vGslPJ/8rv76cR/eU/dz6vjz++fBkH8AZrxuLYniTJitAPzEQcj8t+sYN75uJSIjrq5/m+2sO61WAgvvcH6rMOtdOPA5/OBh1zGc/XOrZmnpLCsBcbT+Vdj9Efzg99CjlT/74RFwzavQsRu8cRU8PRR+n2jFNXhq8yNG7ujcF4ZeARteg/ISa9tnc6xGm5c/Y73PzfHBbDxPBXYy1WAxxaiSHP4Q+QrVm9v2Py2lGnG20KfjB7VSyvt2/g+O74bzfmnd1nOlS39rJMVZl+tPfgdr/lHXxBJjFXaHRUDBoaZff9DF1u3FVU9ZRfANHdsNH822mkZe9Ur922yX/gEmPw47FsOnDWYcnsqHZQ9B6jg48zbXrx8eAdOes0afljmsjHRsFyz7PxhwkZW0eaJjVzjzFutWWtGRuu3bF3nv8+3su6CsEJ4ZbiWzmf+BAT+A5GHund+wgN5ZTVgbC+zWCE5mRMRKBed/+zxwn39iUu3DR7Ph+y2u92evs+oXHFWWWsPsG153fk6PkXDpPJeXnD17Nr179+auu+4C4JFHHiEiIoLPPvuMoqIiKisreeyxx5g2bVqLvpWysjJ+9rOfsX79eiIiInj66ae58MIL2bZtG7fddhsVFRXU1NTw3nvv0atXL2bMmEF2djbV1dX87ne/Y+bMmS16PaV8whj48mnonAbDpjd//MljzreXfA8f/7rx9prK5juAi8Ckh+FfU6xC9fMc/h+qKof3fgxRHeCH/3A+wnL2z62EbfXfrSn8Z/3U2v7pHOtW4+V/aX5kJnm41TZg1R9g73ImnsqDzyMgPAqmv+DeyE5zNjoZefNmB/iCb633sqygbtuBVVay5u71bWv/BYrATqZcFJMlVR+jusYQHqad0JWfNEykmtvuhpkzZ/LLX/6yNpmaP38+y5Yt47bbbiMlJYXjx49z9tlnc+WVV7ZoFYDnnnsOEWHLli3s3LmTSy65hN27d/Piiy9y7733cuONN1JRUUF1dTVLly6lV69eLFmyBLAWWFYqIBxYZd0+u/wvzXfQBtddrjskWTMBnXGngLnvOTDoEmvW3Zm3WbcVwUo0vt8C178D8T2cnysCk229kT76Naz6oy0WA4Mmu397rnM/QODUcau1ZY2tNcCBz72TYPi6A/zyuY2L6KvacLkeHwjsZMrFD8MRk0TZ8RIGdo/3Q1CqXWhiBAmwai2cLkfQG25b0qqXHDNmDLm5uRw5coRjx47RuXNnevTowV133cWaNWsICwsjJyeHo0eP0qOHiw9rJ7788kt+8QurGd+QIUPo27cvu3fv5pxzzuHxxx8nOzubq666ikGDBjFy5Eh+9atf8Zvf/IbLL7+c888/v1Xfi1Je98XTVj+k0Te4d/ykOY0bU0bGwpR5tgWAPVhO5KLfwT/Oh6+ftV5n72fWaNO4/weDL2363LBwOO1S2LWk/pIpBz53f2Rm5RM0uoVpbw3gjWTEB8ut1OPv5Xp8ILBrppwUmdVExPLHqhlkZetvzMqPfFQAee2117JgwQLeffddZs6cyZtvvkleXh4bNmxg06ZNJCcnU1bmZuO+Ztxwww0sXryY2NhYpk6dyooVKzjttNPYuHEjI0eO5Le//S1z5/qvb4tStXI2WCNT59wFEdHundNUXY2nP789R1n1TV88bdX8vHktxPdy3R+poVXzXI/MuMPXyYivC7wDcDaepwI7mbL/MNi7znZKhSue5dPwiZpMKf/yUQHkzJkzeeedd1iwYAHXXnsthYWFdO3alcjISFauXMm3337b4muef/75vPnmmwDs3r2bQ4cOMXjwYPbv30///v255557mDZtGllZWRw5coQOHTpw0003MWvWLDZu3OjR96NUk2wz6iZmTG96RuwXT1sdzsc2UZztjGNjSsdeS57+/GbNt9VUGuuPqbEKtnd86N75niZDvk5GfF3gHYCz8TwV2Lf5wPrLkzB473a4aQFh3Ycy/Ouv2artEZS/+aAAcvjw4RQXF5OSkkLPnj258cYbmTp1KiNHjmTs2LEMGTKkxdf8+c9/zs9+9jNGjhxJREQEr732GtHR0cyfP5833niDyMhIevTowUMPPcS6deuYNWsWYWFhREZG8sILL3j1+1OqlsP6dQLO16/Lmm/Nviv53vqletdH3vuZ8+Tnd/ncxku7VJW5f5vN09torm5hejMZ8WWBt8PaeLVr73m4Np6/BX4yBVazMoC8fdB9KCNTE3hn7WGqqmuICA/swTWlWmrLlrpZhF27dmX58uXExzeuDywpKXF5jX79+rF161YAYmJi+Ne//tXomNmzZzN7dv2lIyZPnszkyZNbG7pS7nO1ft2S+62vJw5ai+Lak5byopYtFuxLno4seZoM+WCh3jYXYLPxPBUcmUgXezJlLWI4KjWB0spq9h3TTuhKKRV0jHE+MgNQXmwlGl8+3Xj0x93Fgn3N09ts3riN5uWFepVngmNkKqYTxCXXJlMjUxIAyMouYHAPndGn2q8tW7Zw880319sWHR3NN99846eIlGpGxSn44Oeu9yekwm0fwV9G0WjGGgTGjC9v3GYLsZGZ9q7ZZEpEegP/BpKx/mW/ZIz5a4NjbgR+AwhQDPzMGLPZq5EmDbRu8wFpXePoGBXO1pxCrh3b26svo1QwGTlyJJs2bfJ3GEq5pzAb3r7eKt4efpW1/EmjhORhq6Glr6fneyIEa36UZ9wZmaoCfmWM2Sgi8cAGEfnUGLPd4ZgDwERjzAkRuRR4CTjLq5EmDYBdHwMQHiYMT0kgS4vQlZcZY1rUEFM5Z1ytaq/al6z5dQlHx251idMN78Jpk2v3O637aYsia0/oyJJy0GzNlDHmO2PMRtvjYmAHkNLgmK+NMSdsT9cA3v/VIWkgnMy11vMBRqUksP1IEZXVThaMVKoVYmJiyMvL00TAQ8YY8vLyiImJadPXFZEpIrJLRPaKyOwmjrtaRIyIjLU97ycipSKyyfbnxbaLOoQ1XL/yZC5UlMAFD1iJFDRd9xOA668p5UqLaqZEpB8wBmiqION24CMPYnKui8OMvpQzGJmaQHlVDXuOljCsVyevv5xqf1JTU8nOzubYMRdrevlJWVlZmycm7nIVW0xMDKmpbXc7RkTCgeeAi4FsYJ2ILG4wgo5tdP1eGn+G7TPGjG6LWNsNZ7P1MLDuFWuhYnfo6I8KEm4nUyISB7wH/NIYU+TimAuxkqnzXOy/A7gDIDk5mYyMjNp9JSUl9Z431OFkPuOB7V9+SG5yEaUnrRGpBSu+4YLUSHe/jVZrLj5/CuTYQOPzVElJCXFxcf4Ow6mmYmtNg1EPjAf2GmP2A4jIO8A0YHuD4x4F/gDMasvg2qUQXDJEKVfcSqZEJBIrkXrTGLPQxTGjgFeAS40xTleRNMa8hFVPxdixY016enrtvoyMDByfN1JVDuvuYVj3KIalp1NTY3h87SdUxPUgPX2kO9+GR5qNz48COTbQ+DwVyPEFUGwpgGO1cjYN6jZF5AygtzFmiYg0TKbSRCQTKAJ+a4z5wqfRtgcdujhfUDgQCsiV8jJ3ZvMJ8E9ghzHmaRfH9AEWAjcbY3Z7N0SbiGhrhoetPUJYmDAiJYEtuqyMUqoZIhIGPA3c6mT3d0AfY0yeiJwJLBKR4c5G4F2Nrgfq6Gb3o6vov/8NJpYfo2x1N/b3v5nc5Ik+f934oj2MOVWAIIhDe4PqsGh29bqW3AbvVaC+fxDYsYHG5ylvxefOyNQE4GZgi4hssm17COgDYIx5EZgDJAHP22ZCVRljxnocXUNJA2uTKYCRqQm89tVBKqpqiIoIjv6jSimfyAEc+6Sk2rbZxQMjgAzbZ1QPYLGIXGmMWQ+UAxhjNojIPuA0YH3DF3E1uh5AI3R1subDVy/U1i3FlB9j2N4XGDZ0qG/rkIqOwMt3QkIvmPBL+Oovte0DwifNYdioGQxrcEpAvn82gRwbaHye8lZ8zSZTxpgvsfpHNXXMT4CfeBxNc5IGwuG1VvdcEUamJFBRXcPuo8WMsDXyVEq1S+uAQSKShpVEXQfcYN9pjCkEutqfi0gG8IAxZr2IdAPyjTHVItIfGATsb8vgfcLVci3urh/XGhWn4O3rrC7mt38CycNhvO//a1DK34JrOCdpIFQUQ0kuYC0rA7BF+00p1a4ZY6qAu4FlWO1b5htjtonIXBG5spnTLwCybCPvC4A7jTH5Pg24LbR1AXhNDbz/U/guC67+p5VIKdVOBMdyMna1Cx7vhfhk+nTpQKeYCLKyC7l+vH9DU0r5lzFmKbC0wTanHR6NMekOj9/DmmATWrzRQdyx6WZzXb4znoAdi+GSx2DwlNbFrNqNRZk5PLVsF0cKSumVGMusyYOZPial+RMDVJAlUwOtr/n7oN8ERIRRqYlsySnwa1hKKRVwJs2BRT+Hmsq6bS3pIG5vumm/VVh42HoOdQlVbbJlS9r6ToBz7vZO/CpkLcrM4cGFWyitrAYgp6CUBxduAQjahCq4bvMlpEJ4dL0i9OiIMLbmFJE2ewkT5q1gUWZOExdQSql2YtQM6DESwsKt+XQRMS3rIO6q5mrZQ5CzAb7+Gyz+Rf3RryMbYct/vfUdqBD11LJdtYmUXWllNU8t2+WniDwXXCNTYeHQpX/tgseLMnP4Yo/VrdoQGtmtUkp5zcnjMHQaR06UkXIsA4ZNd/9cV7VVJ4/Byxc53+frAncV9I4WlZFT0LAzvuWIi+3BILiSKbDqpmwjU08t20VFdf111OzZrSZTSql27eRxKDwE4/8fJzhFypGlkLMe+p7r3vmuaq46docrn7Vm7TmjHc4VdTVROQWlpKxZwU1n92HfsZN8sMn13aOYyDAOHj9Jv64d3b5+oNRcBWcytecTqKl2mcUGc3arlFJecWST9bXXGApOFYKEwf4M95OpSXOs2XnGYTH5yFiY/DgMvtRaeNjTAncVkpzVRP3h411EhMGNZ/WlT5cO/OmT3fVu9UWECVXVhh88vYobz+rDwOQ4XszY7zRZcqfmqq2TrSBMpgZCdQUUHqZXYqzT4cJeibF+CEwppQLIkUzra8/Tqfp2I/QaYyVTFz7k3vlDLgPCIKoDVJxsPJtv0pz6BerQsgJ3FbKc1UQBdIuP4ffTRgCQFBfdKNk5d0ASf1m+h3+v/hbHe045BaX8+r0sducWc27/rjz6v+1Oa67+uGwn08ek+KXAPTiTKYC8vcyaPLTeGwYQGxnOrMmD/RScUkoFiCOZkDQIYjpZz/unw5d/gbKium1N2bcCTBVc9xb0d7IEjT2pcrd1gqon0G5TeZOru0PfF5bVPp4+JsXp9/vED0fy2faj5BaX19teUVXD8yv38fzKfU28bhljH/uMglMVVNU0XQLU8Dakp+9/ECdT+5h+1g8AmPPBVorKquiZEMNvpgwJmX+QSinVakcyod95dc/TJsIXf4Zvv3avD9TOJRCT2PRtwVEzNHlqBW+MnDSXDPgrWftk2/cu97l71+hYg0TKToB3f3oOP39zA8dLKhrtj4+O4OJh3Xl7rZPbz1jv8x3/Xk9EmPDZjlwqqmtqt3s6chVcrREAOnaD6E61RejTx6Twx2tGAfDSzWM1kVJKqeLvofiIdWvPrvdZVnuEA6uaP7+6CnZ9BKdNgfBI38UZwhZl5jBh3gqnbXueWrbTo9YA9mTMXuZiTwbsr+G43zjZ7wvGGJ7P2MtP/7OB1M6xxDRYL7cld41cJV29EmMZn9aF3142jNjI8EbXf3T6CJ68ahQpLs6PjQxnb24JS7d+X5tI2XnamiH4RqZE6s3oAxjQLQ6AfcdKGJmqa/Qppdo5h+LzWpEx0Odsq26qOYe+hrICGHq5D4ILfc5Gnn69IItPt39PeZUhp6DM6XnuTp5y1afpN+9lsXJXLp9tP+oyWWvpyJerkS3H/T0TYuiZEMOGQwVceXov/njNKD7e+n3dyFkLR8ZmTR7cZAmP/Tqu4nN1/pNXjWT6mBTSZi+h/k1AiyeT14IvmQLbgsff1D7tm9SR8DBhb26JH4NSSqkAcWSjNXuv56j62/unw2ePQPFRiE92ff7OJdYo1gAX/aSUy2TjVEUVjy1pXCBdUV3Dki3f079rR2Ijw50WaPdIiHHrtV39p19eVUPmoQJOVjS+dlPnNdTcbciG+48UlnGksIypI3rw1+tGIyK1NVEZGRmkp6e79bp2zSVL9mNcJWfNne+LyWvBm0xtWQCVZRAZQ1REGH27dGDfMU2mlFKKI5nQbQhENejX0z/d+nrgcxh1rfNzjbGSqQEXNT5fAc6TjV/N38yTS3dwrKScGmfDHlg1PyseSG90vl11TQ2H80/Ru0sHl6+97mA+ItZfU0MpibF8/usLmTBvhdNkwQA/fWM9N57Vl7zicv706e5GyUZ5VTWPL93hdGTrdx9s5WhRGc9n7HOaDG7OLkREXMbeEk0lS56e39zIV2sEX80U2IrQDZw4ULtpQPc4HZlSSiljrGTK8RafXY9RVlF5U7f6vs+y+kcNucxXEQY9Z7fZqo2hsLSSX1w0iC4do5yeZx/5mD4mhSevGklKYiyClQTdfeEAyipr+OHzX7H5cEGjc40xvLHmW65/aQ1dOkYR3URN0qzJgxvVFEVHhHHRkG6sO3iCH726lvv/u7leTdWv5m/m7Cc+Y/icZS4LwIvLqnjyo50UllY63R8sPR4d33+w3n/7LcDWCtKRqQHW17y90H0oYNVNZezKpaq6hojw4MwRlVLKY0U51pIvzpKpsHBIu8BKpoyxalAb2rnEukV4mhsz/oKYJ7PdXC2HUl5Vw30Xn0Za147Njnw4GzmZPiaFW/+1jpkvrebG8X34eNvR2pqkPl06sOZAPhcO7sZfrhvDyp25LmuSmrrNVV5VzdlPLOfEqfoJUbUxnDhVyU8n9uetbw412g/QKzGGT++byKSnV9Vrc1C3P3h6PHpyG9KZ4EymujgkUzYDu8dRWW04lH+K/raCdKWUanfszTqdJVNg9YzasRjy99f9Yupo5xLocw507Oq7GP2sta0JqmsMzy7f43K/48gTNF3z48zA7vG8//MJXPX8V/zzq4O12+01SZcM686LN40lLKz5miRXt7miI8IpcJIogdXLadbkIQzqHu80Gfz15CF0jI5g9pQh2uOxgeBMpmI6WetD5dU17xrQzbq3v+/YSU2mlFLt15FMCIuA5OHO9/e/0Pq6f2XjZCr/ABzdCpOf8G2MbaTh6NP9Fw8irVsccz7Y6rQm6MmPdrhMeHKLy7j37U2s3p/H2L6JbD1SRFll3fR6d0ae3NEtPppqF0VX244UExbmeU1ScwXYzSWDrU0WQ1lwJlNg1U05JlPdrQRqb24JFw9rYpaKUkqFsiOZVvlDpItbLl36Q6dU2L8Kxv2k/r6dS6yvIVAvZY0+ZVFaWdeY8Vf/zWrynKNF5Vz/0hquOiOF6hrD31bsJaeglKQvPqW8qpqqGsNT14zi2rG9fdoU8zsnt9DAezVJ7hRgN5cMelogHmqCOJkaALuX1T7tFBNJ9/hondGnlGq/7MXnQ69wfYyINatv5/+gptqqo7LbuQSSR0Lnfr6O1Oee/GhHbSLlqEuHSKIiw53W/MTHRHCksJRZC+onXXknKxDg11MGc+3Y3oBvkwlfrzurI0veF7yV2kkD4WQulBXWbhqoM/qUUu1ZwbdQesJ1vZRd/3SrKed3m+u2lRyDw2sCalSqqS7irpRVVvPXz/ZwtMj5jLQTpyqZPWWI8w7a00aQ8UA6XeMaz8YzwH/WHGrV99FSzmbjebsmafqYFL6afREH5l3GV7Mv0kTKQ0E8MlW3Rh8pZwDWjL5Fm3Iwxnit14VSSgWN5orP7dIusL4eWFX7+cnuj8HUBEwy5U6ReMNbbVec3pNl245y4PhJYiPDnI5M9UqMbXZkJs/Jum/QdlP/deQo+IRYMtWR4rIqjhWX072Te51klVIqZBzJhPAo6D6s6ePik61j9mfAefdZ23YugYQ+0GOkz8N0h3WbrnGR+BNLd3D5qJ78L+u7RsnWi6v20zUuijduH09eSUWzS5K4Sk58fZvNHVqTFFyCN5nqkgZIg/YI8QDsPVaiyZRSqv05kmnN4ouIbv7YtImw4V/WShI1VbBvBYz9sfPeUz5iH1nKKSglZc0KHrj4NBLjonhj9bcub9PlFpcz4pFlVNcYKqsbz3qLCg/j/EHdap+3ZnTHFx2yVWgL3mQqIhoS+9Rf8Li7rT1CbgnnDgjdHilKqcZEZArwVyAceMUYM8/FcVcDC4Bxxpj1tm0PArcD1cA9xphlzs4NaDU1cGQzjLzaveP7p8M3L1jrnJYVQnV5m97ic3Yb7/7/bsYAXeOiiY+OoLi8qtF5nTtEMn1MCv9y6MPkyHEmXGtHdxxvs7VmoV7V/gRvMgW29gh1yVSPTjF0jApn37GTfgxKKdXWRCQceA64GMgG1onIYmPM9gbHxQP3At84bBsGXAcMB3oBn4nIacYY56vFBqoTB6C8sPl6Kbu+54KEW7f6io5AbGerWWcbcbYki8FKlr6efRFLt3zndHTo4SuGM31MCp9sO+rzGW/e7JCtQluzs/lEpLeIrBSR7SKyTUTudXLMEBFZLSLlIvKAb0J1wt5ryrbio4joGn1KtU/jgb3GmP3GmArgHWCak+MeBf4AOM6Lnwa8Y4wpN8YcAPbarhdc3C0+t4vpBKljYe9nVvH5aZdCeNv9fu1qSZaCU5VERYQ5Xb/Ocf20tpjxppS73PnJqQJ+ZYzZaPutboOIfNrgN7584B5gug9idC1pAFQUQ0muVVAJDOwWx+r9eW0ahlLK71KAww7Ps4GzHA8QkTOA3saYJSIyq8G5axqcG3z3c45kQkQMdBvi/jkdu1n9pgD2fAJZ82HUDN/EZ5NXUs6cxdtc7nccWWrqNp3OeFOBpNlkyhjzHfCd7XGxiOzA+qDZ7nBMLpArIm07p9ZxwWNbMjWgexwLM3MoKa8iLjq472IqpbxDRMKAp4FbPbzOHcAdAMnJyWRkZABQUlJS+9hfRm9fiXToS+YXXzXa5yy+7kdXMXjXMmrHdk4dp3rR3ezasYPc5IleienrI5W8t7uSvDJDUoxwRvcw1nxfzalKGJscRtaxGiocuhdEhcFlfardfi8TgcfPDgOselkK95CR4XrtvNYIhL/bpmh8nvFWfC3KNkSkHzAGh3oDv6ptj7AX+k0ArF5TAPuPlTAqNdFPgSml2lgO0Nvheaptm108MALIsPWg6wEsFpEr3Ti3ljHmJeAlgLFjxxp7LY3f62pqquHrb2H0DU7jcBrfM3eDqb/gbXhNOcOO/JdhMx/2OKRFmTm8sXwLpZVWGUZemeHTQ9WkJsay4NZxDO4RX382X4COLPn977YZGp9nvBWf28mUiMQB7wG/NMYUtebFXP1WB63MDk01F0gE2ZtWsr+4LwD5JdavOR+uWkd+SmRrwnQqkLPrQI4NND5PBXJ8ARTbOmCQiKRhJULXATfYdxpjCoHaKb4ikgE8YIxZLyKlwFsi8jRWAfogYG0bxu65vL1QUeJ+vRRAYXbLtreQswJzgBoMg3tYbWy0yFuFCreSKRGJxEqk3jTGLGzti7n6rQ48yA63D6RPhwr62M6trK5hztcfE9W1N+npLagdaEYg/7AHcmyg8XkqkOMLlNiMMVUicjewDKs1wqvGmG0iMhdYb4xZ3MS520RkPlbpQhVwV9DN5Gtp8TlAQioUHna+3RshuSgw/67A+SK+SgWzZpMpscbE/wnsMMY87fuQWqhBe4TI8DD6JHXQGX1KtTPGmKXA0gbb5rg4Nr3B88eBx30WnK8dyYTIjtD1NPfPmTQHPrwHKh2SnshYa7uHdh8tJjxMqKpp3FSzLbuIK9VW3BmZmgDcDGwRkU22bQ8BfQCMMS+KSA9gPdAJqBGRXwLDWns7sEWSBlizUBxWPx/YLU57TSml2o8jmdDz9NrPQLfYZ+0tn2vd2ktItRIpD2bzGWOYv/4wDy/eRkxkGBVVhorqugpzbV2gQpU7s/m+BJpcX8AY8z1W0WbbKz0B1RUwN6n2w2BA91Gs3JVLZXUNkeHNttJSSqngVV0F32VZS8G01KgZHiVPjgsN90iIoWenGDYeLmDCwCSemTmar/fmaesC1S4Ed++ArPmw+V3bE2Pd///wHtJHPMIL1b05lH+qdnafUkqFpOO7oKq0ZfVSXtBwOZjvCsv4rrCMqSN68LcbziA8THSxXtVuBPewzfK51npSjipLGbP7WcBao08ppUJW1nx4zdbe79PfWs/biKvZepuzCwkPa7vFkpUKBMGdTLmYwht58ggAe49pMqWUClFZ860C8tIT1vPi763nbZRQuZqt52q7UqEsuJMpF1N4JSGV5E7R7MvVInSlVIhaPrf+TDywni+f6/OXLrStn+eMztZT7VFwJ1OT5lhTeR3ZpvYO7B6nI1NKqdDl46abrnybd5IfvvCVbYJP/dt5OltPtVfBnUyNmgFXPAvRCdbzTinW81EzGNAtjv25JRjTuM+JUkoFPVfNNb3UdNOZtQfymf7cV+SfrODt/3c2T11zOimJsQiQkhjLk1eN1IJz1S4F92w+sBKqiGiY/yO47s3aGS0Du8dRXF5FbnE5yZ1i/BykUkp52fCr4Ou/1t/mpaabdo6tDxI7RFJUWknfpI7889ZxpHW1FhfW5EmpYB+ZsrN3/T1e1wnd3hJBZ/QppUKOMXDoa4jtYhuJEkjoXTsy7w321gc5BaUY4MSpSgzwk/PTahMppZQl+EemALr0BwmDvD21mwZ2t5KpvcdKOHdgV1dnKqVU8NmfAdnr4LKnYdztPnkJZ60Pagw8t3IfN5zV1yevqVSwCo2RqYhoSOwDx3fXbuoeH01cdISOTCmlQosxsOoPEN8Lxtzks5fR1gdKuS80kimwbvU53OYTEQbojD6lVKg5+CUcWg3n3Wf9IukDNTWG2Cjn6/xp6wOlGgudZCppEOTthZq6RTUHdOuovaaUUqFl1R8grgec8SOfXN4Yw5zFWzlVUU1EmLY+UModoZNMdR1krU9VVNdjZWD3OL4vKqO4rNKPgSmllJd8+zUc/AIm3AuR3p+lbIzh8SU7+M+aQ/z0gv48dc0obX2glBtCowAdrGQK4Pgeq36Kuhl9+4+d5PTeiX4KTCmlvGTVH6FjNzjzVrcOt7c2yCkoJWXNCmZNHtxkMvTnT3bzypcHuPXcfsy+dAgiwg/P8F3fKqVCRQglU/b2CHtg4CTAYUZfbokmU0qp4HZ4LexfCRc/ClEdmj3c3trAPiMvp6CUBxduAep6Qzn2kYqPiaCorIrrxvVmzuXDENHFipVyV+jc5uvYzeqE7tAeoU+XDkSECfu0CF0pFexW/RE6JMHYH7t1uLPWBqWV1Ty2ZDtFZZWN+kgVlVURLsL4fl0IC9NESqmWCJ2RKRHoOrBee4TI8DD6de3IXm2PoJQKZjkbYO+nMOlhiI5z6xRXLQyOl1Qw6pFPCA8TqmvqL7dVbQx//nQ3V52pt/aUaonQGZmCRu0RwDajT0emlFLBKGs+PDMCXr4IEOjofgNiVy0MkjpGMWvy4EaJlJ32kVKq5UIrmUoaCMVHoLy4dlN1jWHfsZOkzV7ChHkrWJSZ48cAlVLKTVnz4cN7oPCwbYOBj35tbXfDrMmDCXfS2uB3lw/jrgsHkuIi2dI+Ukq1XGglU/Yi9DxrdGpRZg6rdh8DwFBXgKkJlVIq4C2fC5UNRokqS63tbpg+JoXk+GiiIqyP+YatDWZNHkxsZP3GnNpHSqnWCbFkyt4ewUqmnlq2i8rq+kPZpZXVPLVsV1tHppTyMRGZIiK7RGSviMx2sv9OEdkiIptE5EsRGWbb3k9ESm3bN4nIi20fvROF2S3b3sCJkxUcKSzjFxcO5LUpHflq9kX12iJMH5PCk1eN1D5SSnlB6BSgQ92Cx7YidF1bSqn2QUTCgeeAi4FsYJ2ILDbGbHc47C1jzIu2468Engam2PbtM8aMbsOQm5eQ6nCLr8F2N3xzIA+AcwYkUXLQ+Wj89DEpmjwp5QWhNTIVEQ2JfWvbI7i69681AUqFnPHAXmPMfmNMBfAOMM3xAGNMkcPTjlh3/wPXpDnWL4eOImOt7W74el8eHaLCGZWa6P3YlFL1hFYyBdatvuNWMqU1AUq1GymA4zBOtm1bPSJyl4jsA/4I3OOwK01EMkVklYic79tQ3ZRyJpgaiEkABBJ6wxXPwqgZbp2+el8eY/t1qa2ZUkr5Tmjd5gOrCP3AF1BTUzt8Pfd/28k/WUHXuCh+e9kwHdZWqp0yxjwHPCciNwC/BW4BvgP6GGPyRORMYJGIDG8wkgWAiNwB3AGQnJxMRkYGACUlJbWPvaXfgbfpi7Bm9NOUx9haIuQDbrxOQXkNe3JLGZNYTkZGhk/i86ZAji+QYwONz1Peii/0kqmkgXULHif2YfqYFCae1o0xj37KbRPSNJFSKjTlAL0dnqfatrnyDvACgDGmHCi3Pd5gG7k6DVjf8CRjzEvASwBjx4416enpAGRkZGB/7BXGwOZfQtr5nDPlmhafvnjzESCTGy8ez+m9E70fn5cFcnyBHBtofJ7yVnzNjv+KSG8RWSki20Vkm4jc6+QYEZFnbbNoskTkDI8ja63aNfrqOqF37hjFoO5xrD2Q76eglFI+tg4YJCJpIhIFXAcsdjxARAY5PL0M2GPb3s1WwI6I9AcGAfvbJGpXDq+FEwdg1HWtOn31vuPEx0QwvFcnLwemlHLGnZvpVcCvjDHDgLOBu+xTih1civUBNAhrCPwFr0bZEg3aI9iNS+vCxm9PuOz6q5QKXsaYKuBuYBmwA5hvjNkmInNtM/cA7rb9QrgJuB/rFh/ABUCWbfsC4E5jjH9/88p6ByJiYdiVzR/rxOp9eZyV1oWIcK2XUqotNHubzxjzHVZNAcaYYhHZgVXY6TjleBrwb2OMAdaISKKI9LSd27bsCx47jEwBjO/Xhbe+OcTO74sY3iuhzcNSSvmWMWYpsLTBtjkOjxuNqtu2vwe859voWqCqHLYuhCGXQXR8i08/UlDKwbxT3HxOP+/HppRyqkW/tohIP2AM8E2DXW7NpGkTItbolK09gt24tC4ArNNbfUqpQLbnEygrgNNbe4vP1l+qf5IXg1JKNcXtAnQRicP67e2Xzma5uHkNpzNhwLsV/0Oq4ul8LIvVDa7XJUZYsm4X/Sq/bfE1A3lGQiDHBhqfpwI5vkCOLWhtfgc6dof+F7bq9K/35dG5QyRDerR8VEsp1TpuJVMiEomVSL1pjFno5BC3ZtK4mgkDXq74D98Ay1eSfs6Z9YbJz/8+k6/35TFx4kREpIkLNBbIMxICOTbQ+DwVyPEFcmxB6VS+NTI17icQ3vLJ1sYY1uzP4+z+SYSFtewzTinVeu7M5hPgn8AOY8zTLg5bDPzINqvvbKDQL/VSdkm2IvS8BkXo/bpwrLicQ/mn/BCUUko1Y/siqK6AUTNbdfqh/FPkFJRy7gC9xadUW3LnV58JwM3AFttsF4CHgD4AtrWulgJTgb3AKeA2r0faErUz+vZArzG1m8fb6qbWHsinb1JHf0SmlFKubX4Xug2Bnqe36vTaeilNppRqU+7M5vsSaHK82DaL7y5vBeWx2gWP6xehD+wWR0JsJOsO5nPt2N4uTlZKKT/IPwCH18Ckh62JNK2wen8e3eKjGdAtzsvBKaWaEppNSBoseGwXFiaM69eZdQdP+CkwpZRyIWs+IG6vvdeQMYav9+VxTv+kFteEKqU8E5rJFFid0BuMTIFVN3Xg+Elyi8v8EJRSSjlhjNWos995kJDaqkvsO3aSY8XleotPKT8I4WRqkFWAXlNTb7O939QGHZ1SSgWK7PWQv7/VhedgLSEDaPG5Un4Q2slUVRkUHq63eUSvBGIiw1h7UJt3KqUCRNY7EBEDw6a1+hKr9+fRKyGGPl06eDEwpZQ7QjeZqm2PUP9WX1REGKN7J7JOkymllL9lzYdnhsO6V6yi890ft+oyNTWG1fvyOGdAV62XUsoPQjeZcmyP0MD4fl3YfqSI4rLKNg5KKaVssubDh/dAYbb1vLLUep41v8WX2nW0mBOnKrVeSik/Cd1kqmM3iElwmkyN7deFGgOZhwraPi6llAJYPtdKoBxVllrbW+hr7S+llF+FbjIlYt3qy2ucTJ3RtzNhgt7qU0r5j31Eyt3tTVi9L4++SR1ISYz1MCilVGuEbjIFLtsjxEVHMLxXAmsPaDKllPITVy0QWtgaobrG8M2BPJ3Fp5QfhXgyNRCKv4Py4ka7xvXrwqbDBZRXVfshMKVUuzdpDkQ0GEmKjLW2u2lRZg5nP7mc4rIqPt76PYsyG60vr5RqA6GdTCW5LkIf168z5VU1bM0pauOglFIKq9P5eb+0PRFI6A1XPOt2B/RFmTk8uHALx4rLAThxqpIHF27RhEopPwjtZKrradbXvL2Ndo3tZzXv1LoppZTfJA20vv58Ddy3tUVLyTy1bBellfVH1ksrq3lq2S5vRqiUckNoJ1Nd0pwueAzQLT6a/l07sk7rppRS/nLigPU1sU+LTz1SUNqi7Uop3wntZCoiGjr3g+O7ne4e168L6789QU2Nadu4lFIK4MRBiOsBUS3vWt7Lxcw9V9uVUr4T2skU2NojNL7NBzC2X2cKSyvZndu4QF0ppXzuxLfWL3yt8MDFp9Gw13lsZDizJg/2OCylVMuEfjJlauDoVngkEZ4ZUa+78Pg0e92ULnqslPKDEwdbnUx16xSDATp3iESAlMRYnrxqJNPHpHgxQKWUOyL8HYBPZc2HAxm2J8Za9PjDe6yno2bQp0sH4qPDeWLJDuYs2kqvxFhmTR6sH0ZKKd+rqrAadLYymXp77SESO0Sy+sFJxESGezc2pVSLhPbI1PK5UN1g/T2H5Ro+2HSEUxXVlFZWY4CcglKdWqxUkBKRKSKyS0T2ishsJ/vvFJEtIrJJRL4UkWEO+x60nbdLRCa3ScAFhwDTqmQqr6ScT7Z/z1VjUjWRUioAhHYy1cxyDU8t20V1g9pznVqsVPARkXDgOeBSYBhwvWOyZPOWMWakMWY08Efgadu5w4DrgOHAFOB52/V868RB62srkqn3NmZTWW24fnxvr4aklGqd0E6mmlmuQacWKxUyxgN7jTH7jTEVwDvANMcDjDGOHXo7AvZfpaYB7xhjyo0xB4C9tuv5lr0tQguTKWMM76w9zJl9OzMoOd77cSmlWiy0k6lJc6zlGRw5LNegU4uVChkpwGGH59m2bfWIyF0isg9rZOqelpzrdScOQkQMxCW36LRvDuSz//hJrh/f8t5USinfCO0CdHs34Y8fhFPHoWM3mPxE7fZZkwfz4MIt9boI69RipUKXMeY54DkRuQH4LXBLS84XkTuAOwCSk5PJyMgAoKSkpPaxu4bvWU+HqK6s+/zzFp33j81lxEZAfMEeMjKct31pqDXxtaVAji+QYwONz1Peii+0kymwEqchl8G8vjD6hnrLNdhn7c3933byT1aQ1DGK310+TGfzKRV8cgDHAqJU2zZX3gFeaOm5xpiXgJcAxo4da9LT0wHIyMjA/thtO34LKcNbdF7BqQo2fLacmWP7MnnSCLfPa1V8bSiQ4wvk2EDj85S34gvt23x2UR2h93jYv6rRruljUvjqNxcRHRHGlaN7aSKlVHBaBwwSkTQRicIqKF/seICIDHJ4ehlgX2dqMXCdiESLSBowCFjr02iNaVWPqYUbc6ioqtFbfEoFmPaRTAGkTYTvNsOpxmvxxUaFc+6AJJbvyMUYXVpGqWBjjKkC7gaWATuA+caYbSIyV0SutB12t4hsE5FNwP3YbvEZY7YB84HtwMfAXcaY6oav4VWn8qGiuEXJlDGGd9Yd4vTUBIb16uS72JRSLdZ+kqn+6YCBg1843X3R0GQO5Z9i37GSNg1LKeUdxpilxpjTjDEDjDGP27bNMcYstj2+1xgz3Bgz2hhzoS2Jsp/7uO28wcaYj3werL0tQpc0t0/ZeKiA3UdLuE5HpZQKOM0mUyLyqojkishWF/s7i8j7IpIlImtFxP0b+W0p5QyIioP9GU53XzSkOwDLd+S2YVBKqXapFW0R3ll7iI5R4Vxxei/fxKSUajV3RqZew2pk58pDwCZjzCjgR8BfvRCX94VHQr/znNZNgbWu1dCenVi+U5MppZSP2UemEvu6dXhRWSUfZh3hytG9iIsO/XlDSgWbZpMpY8znQONCozrDgBW2Y3cC/USkZY1T2kraRMjfBwWHne6eNKQ7G749QcGpijYOTCnVrpw4aPWXiurg1uEfbDpCWWUN143TW3xKBSJv1ExtBq4CEJHxQF+sqcWBp3+69fWA89Gpi4Z2p7rGsGr3sbaLSSnV/rg5k29RZg4T5i3nd4u2EhEm7NeaTqUCkjfGi+cBf7XNkNkCZAJOZ8K4angHbdTYyxjOjUzkxOp32VHYON+rMYb4KHh71RYSCvbU2xfIjccCOTbQ+DwVyPEFcmwB7cRB6Htuk4csysyp11S4qsbw0PtbERFt4aJUgPE4mbKtd3UbgIgIcADY7+JYpw3voA0be+VfTPL+VSRPnAgijXZfcmwzn27/nvPOv4CI8LqBu0BuPBbIsYHG56lAji+QYwtYVRXWYuvNjEw9tWxXvdUZoG4hdk2mlAosHt/mE5FEW5M8gJ8AnzdYUDSwpE2Ek7mQu8Pp7h8M7U5RWRUbvj3RxoEppdqFwsOAaTaZ0oXYlQoe7rRGeBtYDQwWkWwRuV1E7hSRO22HDAW2isgu4FLgXt+F6wXN1E2dN6grkeHCCp3Vp5TyBTfbIuhC7EoFD3dm811vjOlpjIk0xqQaY/5pjHnRGPOibf9qW6O8wcaYq4wxgT2kk9gbuvR32W8qPiaSs9KStEWCUso37G0RmkmmZk0eTGR4/VIEXYhdqcDUfjqgO0qbCAe/gupKp7svGtKdvbklfJt3so0DU0qFvBMHITwa4no0edj0MSmc2aczIiBYvfCevGqk1kspFYDaZzLVP91aFytno9Pdk4ZqN3SllI+cOAid+0JY8x+/R4vLmTQkmQPzLuOr2RdpIqVUgGqfyVTaBYC4rJvqm9SRgd3jtG5KKeV9bvaYyi0u48Dxk5yV1sXnISmlPNM+k6kOXaDnKJdLy4DVDf2bA3kUlzm/FaiUUi1mDJz41q1kat0Bq/x0nCZTSgW89plMgVU3dfgbqHBeF3XRkO5UVhu+3HO8jQNTSoWs0hNQXgSd05o9dO2BPDpEhTO8V6c2CEwp5Yn2m0z1T4eaSji02unuM/t2JiE2Umf1KaW8x822CADfHMjnzL6diQxvvx/TSgWL9vtT2uccCI9y2SIhIjyM9MHdWLkzl+oa07axKaVCk5ttEQpPVbLraDHj++ktPqWCQftNpqI6QO+zmqybumhId/JOVrA5u6Dt4lJKha7aZKpvk4et/zYfY7ReSqlg0X6TKbDqpr7PgpN5TndPPK0bAtzyz7Xc+vFJJsxbwaLMnLaNUSkVOvIPQMfuENWxycPWHsgnKjyM0b0T2yYupZRH2ncyZV9a5uDnTndn7DqGCBSXVwGQU1DKgwu3aEKllGodN9sifHMgn9N7JxATGe7zkJRSnmvfyVSvMRAeAx/cBY8kwjMjIGt+7e6nlu2iYbmUfdV2pZRqMTfaIpyqqGJrTiHj9RafUkEjwt8B+NW2hVBTAdU11vPCw/DhPdbjUTN01XallPdUVUBRdrPJVOahAqpqDOO0+FypoNG+R6aWzwVTU39bZam1HV21XSnlRYWHrc+bZpKpbw7kEyZWexalVHBo38lUYXaT22dNHkysk5qFq87Q9bGUCjQiMkVEdonIXhGZ7WT//SKyXUSyRGS5iPR12FctIptsfxb7JEA32yKsPZDH8F4JxMdE+iQMpZT3te9kKiG1ye3Tx6Tw5FUjSbGNRCV3iqZbfBQvfb6f5TuOtlWUSqlmiEg48BxwKTAMuF5EhjU4LBMYa4wZBSwA/uiwr9QYM9r250qfBOlGMlVeVU3moQKtl1IqyLTvmqlJc6waqUqHGqjIWGu7zfQxKUwfk0JGRgbp6enklZRz22vruOONDcwcm8qq3cc5UlBKr8RYZk0erKu6K+Uf44G9xpj9ACLyDjAN2G4/wBiz0uH4NcBNbRrhiYNWo+D4ni4P2ZpTSHlVjdZLKRVk2vfI1KgZcMWzEN/Leh7dyXo+aobLU5Lionnr/51N/64deGvtYXIKSjFo2wSl/CwFOOzwPNu2zZXbgY8cnseIyHoRWSMi030Qn5VMJfaFMNcfu98cyAdgXD+tl1IqmLTvkSmwEqdRM+Df0yF/P4y8ttlT4qIjOFle3Wi7vW2Cjk4pFbhE5CZgLDDRYXNfY0yOiPQHVojIFmPMPifn3gHcAZCcnExGRgYAJSUltY9dOfPwViqiOrOlieM+Xl9Grzhhy3rna4a2ljvx+VMgxxfIsYHG5ylvxafJlN2ombDoTji0Bvqe0+zh3xWWOd2ubROU8oscoLfD81TbtnpE5AfA/wETjTHl9u3GmBzb1/0ikgGMARolU8aYl4CXAMaOHWvS09MBassAXDIGVh+HoZNcHlddY/jFyk+4cnRv0tNHur5WKzQbn58FcnyBHBtofJ7yVnzt+zafo6FXQGQHyHrXrcO1bYJSAWUdMEhE0kQkCrgOqDcrT0TGAP8ArjTG5Dps7ywi0bbHXYEJONRaeUXpCSgvgi5pLg/Z8V0RxeVVWnyuVBDSZMouOg6GXA7b3oeq8mYPd9Y2QQTuv3iQryJUSrlgjKkC7gaWATuA+caYbSIyV0Tss/OeAuKA/zZogTAUWC8im4GVwDxjjHeTKTdm8q2trZfSZEqpYKO3+RydPhO2zIfdy2BY07Oj7XVRTy3bxZGCUjp3iCT/VCWHT+htPqX8wRizFFjaYNsch8c/cHHe14B376s15GYy1btLrI5uKxWENJlylJZureie9W6zyRTUtU2wu//dTfxtxV7SB3fX1d6VUnVOHLC+JvZ1utsYw7qD+aQP7t6GQSmlvEVv8zkKj7Bm8+1eBqfyW3z6I9OG06NTDPe9u4lTFVU+CFApFZROHISO3axyAif2HTtJ3skKxqdpSwSlgpEmUw2dPhNqKq3aqRbqFBPJn649nYN5J3li6Q4fBKeUCkonDrpVLzU+Lalt4lFKeZUmUw31GAXdhro9q6+hcwYk8ZPz0vjPmkOs3JXb/AlKqdDXbDKVR7f4aPoldWizkJRS3tNsMiUir4pIrohsdbE/QUQ+FJHNIrJNRG7zfphtSMRq4nn4G8g/0KpL/OqSwQxOjufXC7LIP1nh5QCVUkGlutJaPL2JZGrdwROMT+uCiLRdXEopr3FnZOo1YEoT++8CthtjTgfSgT/b+rwEr1EzAIGs+a06PSYynGdmjiavpJxz5y0nbfYSJsxboUvNKNUeFR4GU+M0mVqUmcNZT3xGTkEpX+45rp8RSgWpZpMpY8znQFPV2AaIF+tXqjjbscFdfZ2QCv3Og6x3rM7FrbD7aDFhIpRV1ujafUq1V1nz4Z+XWI8/e6TeL2iLMnN4cOEWjhZZfe0KSyv1M0KpIOWN1gh/x+o0fASIB2YaY2qcHehqXSsIvPV7ekSPZkj+F2z48CWKOw1ucXyPZpyiqqZ+IlZaWc2jH2wmsXCPV2MNtPeuIY3PM4EcXyDH5ndZ8+HDe6DS1nvu5DHrOcCoGTy1bBellfXX+NT1PZUKTt5IpiYDm4CLgAHApyLyhTGmqOGBrta1ggBcv6fsDPjTy5wZvgfSf9ri+PI/XuJ8e5nx+vcZcO9dAxqfZwI5vkCOze+Wz61LpOwqS63to2a4XMdT1/dUKvh4YzbfbcBCY9kLHACGeOG6/hXTCQZPha3vQVXLi8hddTGOiQyntKLa6T6lVAgpzG5yu67vqVTo8EYydQiYBCAiycBgYL8Xrut/p18Hpfnw9FAmZkyHZ0a4XZTubO2+iDChtLKaHz7/Fd/mnfRBwEqpgJGQ2uR26zOi/kdwbGQ4syYP9nVkSikva/Y2n4i8jTVLr6uIZAMPA5EAxpgXgUeB10RkCyDAb4wxx30WcVuyd0E/dRwBa1aOQ81DUxqu3dcrMZZZkweT2CGSe9/ZxBV/+5LrxvVmyZbv6+3XWgmlQsSkOfVrpgAiY63tWJ8RpyqqeOh9q+tMin4GKBW0mk2mjDHXN7P/CHCJ1yIKJCsfb7zNoeahOQ3X7rP78O7zuO6l1bz0RV0fK/tsP/t5SqkgZ/+MWD7XurWXkGolUg6fHWP7dQHgb9eP4YrTe/kjSqWUF+hCx01ppuahtfq46HKsM3mUCjGjZjT5i9fRojIAkjvFtFVESikf0OVkmtJMzYMnvissc7pdZ/Io1X7Ye0wld4r2cyRKKU9oMtWUSXOsGgdHYZG1NQ+ecDVjJzxMWHewqR6pSqlQYR+Z6h6vI1NKBTO9zdcUh5oHU5iNRMZC5Smo9ny9vVmTB/Pgwi31mvZFhQsdosK59sXVXH1GKqP7JPBixn4tUFcqROUWlREfE0FsVHjzByulApYmU82x1Tysysgg/bxz4e2ZsPge6NgNTpvc6su6mu13yfBk/rZiL/9YtY/3NtbVZmmBulKh52hRudZLKRUCNJlqiYgomPFveO0y+O+tcMv/IPXMVl/O1Wy/30wZwnsbssktLq+3XQvUlQotR4vLtF5KqRCgNVMtFR0PNy6AuO7w+hXw58HwSGKLGnq641iDRMpOC9SVCh25ReUka72UUkFPk6nWiOsO434ClSeh+HvA1DX09FJC5apAvVNsBMYYp/uUUsHDGENucRnd9TafUkFPk6nW+uYfjbfZG3p6gbPlaMIECkuruH/+ZsoqdX0/pYLZiVOVVFYbvc2nVAjQmqnW8lFDTztnBeoPXHwa2QWl/PnT3ezNLeGqM1J45YsD5BSUkrJmhc72U+2aiEwB/gqEA68YY+Y12H8/8BOgCjgG/NgY861t3y3Ab22HPmaMed3X8WrDTqVChyZTrZWQat3ac7bdS1wVqA/t2Ym73tzA7z8srN2ms/1UeyYi4cBzwMVANrBORBYbY7Y7HJYJjDXGnBKRnwF/BGaKSBesNUfHAgbYYDv3hC9jrkumdGRKqWCnt/lay1lDz/BorzT0bM4PhiWT0CGq0Xb7bD+l2qHxwF5jzH5jTAXwDjDN8QBjzEpjzCnb0zWA/TefycCnxph8WwL1KTDF1wHn2rqfa8NOpYKfJlOtNWoGXPEsJPQGxPrTc5RbCyB7g872U6qeFMBxqDjbts2V24GPWnmuV9R2P9eRKaWCnt7m84TjIqYfPwhrX4aSXGu2n4/1Sowlx0niFB0Rxv5jJfTvFtfsNRZl5jRqGqq3CFWoE5GbsG7pTWzFuXcAdwAkJyeTkZEBQElJSe1jd2XuLCcuElZ/+UVLw2ix1sTXlgI5vkCODTQ+T3krPk2mvGXsj2HN87Dx33DBAz5/OWfL0USECcYYLnnmc246uy8Du8fxQsY+p8nSosyceudrzZUKcjlAb4fnqbZt9YjID4D/AyYaY8odzk1vcG6GsxcxxrwEvAQwduxYk55unZaRkYH9sbvePLSe1MpTpKdf0KLzWqM18bWlQI4vkGMDjc9T3opPkylv6ToI0ibC+n/BefdBmG/X2nKc7ZdTUEqKLVk6b1BXnvl0N699fbDe8TkFpfz6vSzWfZtHcnwsL67aVy8RA+2wroLaOmCQiKRhJUfXATc4HiAiY4B/AFOMMbkOu5YBT4hIZ9vzS4AHfR1wbpH2mFIqVGgy5U3jfgLzb4bdy2DIVJ+/nH22X8PM+vEfjuTT7UcbLUdTUVXDm2uczEB0oDVXKhgZY6pE5G6sxCgceNUYs01E5gLrjTGLgaeAOOC/IgJwyBhzpTEmX0QexUrIAOYaY/J9HfPRonJOS4739csopdqAJlPeNHgqxPeE9f9sk2SqKa4K1AXY8egUJv15ldOaq7iYCGpqDGFh4uMIlfIuY8xSYGmDbXMcHv+giXNfBV71XXT1VdcYjpXoIsdKhQqdzedN4RFw5q2w9zPI3+/XUFwtR9MrMZaYyHCnHdbDRSguq+KONzZQXFbZFmEq1S7lnSynuka7nysVKjSZ8rYzbgEJh/Vt9kuuU86SpVhbEgXWLcInrxpJSmIsAqQkxvKna0fx+yuHs3JXLtOf+4p/fL6PCfNWkDZ7CRPmrWBRZqN63iYtysxhwrwV3PrxyVadr1Soqu0xpSNTSoUEvc3nbZ16wtDLIfM/cOH/NW7s2UacLUfTsPWBqw7rpyXH85PX1/Hk0p2121o6209nCyrlmi4lo1Ro0WTKF8beDts/gG2LYPT1fgvDVbLUnHMGJBEXE8HJisaz/f748c567RUaJmtXnN6L/cdK+P2H23S2oFIuHLWNTOltPqVCgyZTvpB2ASQNgnWv+DWZ8oT9NkRDRwrLuPBPGXSMCmfn98VU1RjAGnm6f/4mZi3YTGW1cXndnIJSjhWX0y0+WpuGqnbraFEZItA1TpMppUKB1kz5gojVJiFnPRzZ5O9oWsVVAXt8TARDe8bXS6TsagxEhYfx52tPp3u86/8kzp23nKue+4pfv5dFTkEphrrbgI51Vfaaq9bWbCkVqHKLy0jqGE1kuH4EKxUK9CfZV06/DiI7WG0SgpCrAvZHp43g+RvPpLrG+ejTqYpqrj4zlYemDnV6/kNTh3Dz2f3IPFxARVVNvf2lldXM/XAbX+w5xrPLd/MbD5Mtd/drgbxqa0eLyvUWn1IhRG/z+UpsIvQ6Aza+Yf1JSIVJc9psIWRPNVfA7mptQPuIlqsO7fbt//rqgNPXzT9Vyc3/XOt0X2llNf+3aAvFZZXkFJTyr68OUm5LyOzJlqkxXDqqJ4sys3nkw+2UVTruz6qNTQvklT8dLSrT4nOlQkizyZSIvApcDuQaY0Y42T8LuNHhekOBbm3RQTigZc2HnHWAbQSn8DB8eI/1OIgSKleJhbO1AR1bLzie72ztI1fJWPf4aJ678QyufXG109c9WV7N7z7Y5nRfaWU19/13M/f9d7OL/TX88t1NzP3fdgpPVVJtTKPzW1Ig31zNl9aEKVeOFpUzKjXB32EopbzEndt8rwFTXO00xjxljBltjBmNtZ7VqnafSAEsnwtVDYq4K0ut7XZZ8+GZEfBIovU1a36bhugJZ32qnrxqpNvJgqvbiA9NHcq4fl1IcVGzlZIYwzcPTaKp/uy/njK4ib0wdWSPRomU3ZGCUoxtX1O3CRdl5jB7Yf3bkLMXZvH+xuza/Q8u3KI1YaqRyuoa8k6W0y1eR6aUChXNjkwZYz4XkX5uXu964G2PIgoVhdkuth+Gpb+GylNW8lRdXrc9hEau3DkXXN9GdD3yNYTkTjEuR7ZSEmP5efpA3lxzyOX+x6aPZOXOY073G2DKX77g9N4JLN58pN5twtkLs9j1fTGREWH8Y9W+2luMdmWVNdw3fzNPfLSTEycrGhXol1ZW89iS7ZzRpzNrD+Txuw+26W3Gduh4STnGaFsEpUKJ12qmRKQD1gjW3U0ccwdwB0BycjIZGRm1+0pKSuo9DzQtje/s6K7ElB9rtL1GIjDrXye8pqzxSZWllC15iDX53X0aW1tzFV8i8PjZYUBHa0PhHjIy9tTuu3loOO/triGvzJAUI1x9WjiJtmMu61PNa0VQ4ZDPRIXBZX2qycjIaPX+c3qFs7/wJPPXFzeKt6yyhhdW7UOovXnr1LCEalYVOz/ieEkFFzy10um+0spqHv1gM4mFe+ptD+S/30COLVDZ244k68iUUiHDmwXoVwBfNXWLzxjzEvASwNixY41jHY2zuppA0uL4ujxhjTRVOox+RMYSdsWzMOIamNsFZ/8lx5Qfb/H7EHLvnU068FAT+4Y1UZPUkv0NC+SNMfR/cKnLhCnrkUuY8pcvXI58vX73RUyYt8Lp/qSOUfzm0iH8ekGW02vnl5lG71Ug//0GcmyBSrufKxV6vJlMXYfe4qtjv1W3fK51y6/hbL6EVOvWXkOderVdjEGuuduM7u5vmBCISJO3EeNjIpstwHe1/3eXD2P6mBT++tkep9ePDA9j8+ECTu+dWFvAnlNQSsqaFVrAHiKOFmv3c6VCjVeSKRFJACYCN3njeiFj1AzX9U+T5jQeuQKI6GBt89OafsrSXLLUXM1Xa2rCIsOFyHBh2nNfMbp3Aju+K27U+sHx2k3x9UxCTfRaL7eojDCBJO1+rlTIcKc1wttYd0W6ikg28DAQCWCMedF22A+BT4wxJ30UZ+hxNnI1+FJY+zIs+DHMeAPCtQ2Yv3iyULQ7+11df9LQ7rz8+X7+tmJvo9uM7rZucKeHlidtHbRHl2eOFpXRLT6a8LCm5qQqpYKJO7P5ml1czhjzGlYLBdUSzkauug2GJb+yRq2mPWctTaP8wpPZip5c//5LBvO3FXudnnPE4dagq4TnqWW7nC4y/cdlO91qWGpv++A4k/GB/27mv+sPERURzhd7jjudqaiLWLvH6n6u9VJKhRId+gg0434CJ49DxpPQsStcPLf5c1TIcVWzJQKP/W87XeOi+OvyvfUSot+8l8XX+447PQ/gSEEZlzyzikN5pyhzspTPgwu38NbaQ2w4eKJRH66qGsPq/fkM7dmpUSJVd33nr6vqO1pURmrnDv4OQynlRbo2XyCa+BsY9//gq7/CvD5B2dRTecZZU9Oo8DBGpHTita8PMu/jxqNP5VU1zF+fjau7R3HR4fTp0qFRImVXWlkNBpcNTY2BJfec77KhqqvFsVV9ucW6Lp9SoUaTqUAkAqnjQMKhrBAwdU09NaFqFxw7zIM1i/CP14xi8d3ns+ahSS7PE+DP157utLv8Y9NH8sot45roLh/L/DvPaTZZctW93nEpIeVceVU1+Scr9DafUiFGk6lAteJRMPVHHhotR6NC2vQxKXw1+yJem9KRr2ZfVFuP1DUuusmE54dnpDa51E9zyVBz+50lei1ZSqg9O6ZtEZQKSVozFaiaWo7m5HGrnkq1W+60bmjpTEJ32zo4Xl+bdrbMUVv38+46MqVUSNFkKlC5auoJ8NfRMOFeiO8Bq/7AxMJsyGzQFFSFNHcSnubO96ThaSASkSnAX4Fw4BVjzLwG+y8A/gKMAq4zxixw2FcNbLE9PWSMudIXMebau5/rUjJKhRRNpgKVs6aekbGQ/iAcXgsrH6vdLBCUCyUrzwRjwuMrIhIOPAdcDGQD60RksTFmu8Nhh4BbgQecXKLUGDPa13HWLSWjt/mUCiVaMxWoRs2AK56FhN6AWF+veNYakbruTejoZDFkralS7dd4YK8xZr8xpgJ4B5jmeIAx5qAxJgtwPp2xDRwtLicyXOjcIcpfISilfEBHpgJZU8vRnDzmfLurWiulQlsK4HhfPBs4qwXnx4jIeqAKmGeMWeTF2GodLSqje3wMYdr9XKmQoslUsNKFkpXypr7GmBwR6Q+sEJEtxph9DQ8SkTuAOwCSk5PJyMgAoKSkpPZxU3Z9W0qMwa1jvcnd+PwlkOML5NhA4/OUt+LTZCpYuVwoOQYqTkJUR//EpZR/5AC9HZ6n2ra5xRiTY/u6X0QygDFAo2TKGPMS8BLA2LFjjX0mo7uzGh/fuIpBPeJITz/T3dC8ItBnXQZyfIEcG2h8nvJWfJpMBSuHhZJNYTZiXyh53Svw7k1w/TsQoUWuqt1YBwwSkTSsJOo64AZ3ThSRzsApY0y5iHQFJgB/9EWQR4vKOHdAki8urZRbKisryc7OpqysrE1eLyEhgR07drTJa7WGs/hiYmJITU0lMjLS7etoMhXMbDVVqxwz656nwwd3wYIfw7WvQ7j+FavQZ4ypEpG7gWVYrRFeNcZsE5G5wHpjzGIRGQe8D3QGrhCR3xtjhgNDgX+ISA3WpJx5DWYBekVpRTVFZVXaY0r5VXZ2NvHx8fTr1w8R39fuFRcXEx8f7/PXaa2G8RljyMvLIzs7m7S0NLevo//ThpoxN0F5CXz8G3jtMijKhsIcq8ZK+1CpEGaMWQosbbBtjsPjdVi3/xqe9zUw0tfx5Rbb2yJoMqX8p6ysrM0SqWAkIiQlJXHsmItJXi5oMhWKzr4TDq2G7YvqtmkfKqX8yt79XHtMKX/TRKpprXl/tM9UqMrZ0Hhbwz5UWfPhmRHwSKL1VRdRVspn6hp26siUUqFGk6lQ1dTafp/OgY8fhMW/sLVXMHUjVy1JqDQZU8ptufZFjnUpGRVEFmXmMGHeCtJmL2HCvBUsynR7kqxTBQUFPP/88y0+b+rUqRQUFLT4vJ07dzJ69GjGjBnDvn37+PGPf0z37t0ZMWJEi6/VFE2mQlVCo9IQS3gUrHkB1jwPVQ1mc1SWwvLf1z1vKlnKmm8lX54kY0q1I7lFZURFhNEpVqsrVHBYlJnDgwu3kFNQigFyCkp5cOEWjxIqV8lUVVVVk+ctXbqUxMTEFr/eokWLuOaaa8jMzGTAgAHceuutfPzxxy2+TnP0pzpUuVrb74pnYeiV8HgPwDQ+rzAbXr8CouJh76dQXWHbfhgW3w1HMiGxL6x4rHGPq8pS+OyRupqsrPmwfK4uxKwU1m2+5E7RWq+iAsbvP9zG9iNFLvdnHiqgorr+6kulldX8ekEWb6895PScYb068fAVw11ec/bs2ezbt4/Ro0cTGRlJTEwMnTt3ZufOnezevZvp06dz+PBhysrKuPfee7njjjsA6NevH+vXr6ekpIRLL72U8847j6+//pqUlBQ++OADYmNjG73W0qVL+ctf/kJ4eDjLly9n5cqVXHDBBRw8eNCNd6dlNJkKVQ59qCjMbjybz1UH9ag4KCuEA5833ldVbo1oNaUoB175AXRIgn0robpcF2JWCqsAXW/xqWDSMJFqbrs75s2bx9atW9m0aRMZGRlcdtllbN26tbYNwauvvkqXLl0oLS1l3LhxXH311SQl1e/NtmfPHt5++21efvllZsyYwXvvvcdNN93U6LWmTp3KnXfeSVxcHA884Gx9c+/RZCqUNbW2n6uRq8ufsc55JBGnI1cIzNoLL6U7T8ai40HCYLeTYVR7AbwmU6odOlpcxtAenfwdhlK1mhpBApgwbwU5BaWNtqckxvLuT8/xSgzjx4+v18/p2Wef5f333wfg8OHD7Nmzp1EylZaWxujRowE488wzfTLS1FJaM9VejZph3fJL6A2I9fWKZ+uPXDmTkAodu1rJWGSDYdXIWLjsabj9E+uazuhCzKqdyi0qp7u2RVBBZNbkwcRGhtfbFhsZzqzJg732Gh071i19lpGRwWeffcbq1avZvHkzY8aMcdqpPTq67ucoPDy82XqrtqAjU+1Za0auJs2pOxdafhsxrpv34veU1nSpNlJSXkVJeZW2RVBBZfqYFACeWraLIwWl9EqMZdbkwbXbWyM+Pp7i4mKn+woLC+ncuTMdOnRg586drFmzptWv09Y0mVLONZcs2Y9pSTKGwMk82LIARl7TfAy2ZMfl63vCPhuxslRrupTP5db2mNKRKRVcpo9J8Sh5aigpKYkJEyYwYsQIYmNjSU5Ort03ZcoUXnzxRYYOHcrgwYM5++yzvfa6dtdffz0ZGRkcP36c1NRUHnzwQe666y6Pr6vJlHKtqWTJnXOh/kLM590PW+bDe7dD3l6Y+BtwNbPJIdkBvJ/sfPJb57MRtaZL+UBt93MtQFeKt956y+n26OhoPvroI6f77HVRXbt2ZevWrbXbmyssf+SRR+o9f/vtt+s9dzVK1lLNJlMi8ipwOZBrjHHa5UpE0oG/AJHAcWPMRK9Ep4Kbs4WYx9wIH94LGU/C3uVQdMSaAWgfeTptChxaA0vu9zzZcTayFdsZvn4WSo46P8ebNV2+HFlTQcW+Lp8ucqxUaHJnZOo14O/Av53tFJFE4HlgijHmkIh091p0KvRERMP0F6CyDLa/X7e98DAsvAPnMwipf9z3W6HHiKaTFWcjW/brx/eCmASrBURDYWFw8Evod55n36evR9ZUUDmqt/mU8qm77rqLr776qt62e++9l9tuu61NXr/ZZMoY87mI9GvikBuAhcaYQ7bjc70UmwpVIpCz3skOA9GdYOYbsOguKHI2SiTw4gToOhhOHKjfVPTDe6yu7qnjreVyGo5sYSC2C9y72VoEumFNV3i01drhtctg7I+h52j4/CnXI0tNJXOfPaK3EVWto0XldIgKJy5aKyuU8oXnnnvOr6/vjZ/s04BIEckA4oG/GmOcjmIpVcvV7bTyYuifDj942PlswslPQFmRlZSY6vrnVpZa6w02pfQEREQ5r+maNAeGXA4rH4fVf8dq72AbKWs4suRs5OmDu6zi+lPHrVuXLfm+VUizup/HaPdzpUKUN5KpCOBMYBIQC6wWkTXGmN0NDxSRO4A7AJKTk8nIyKjdV1JSUu95oAnk+AI5NnAe39nRXYkpP9bo2LLorqzJyAC6033gz+i//w2iy49THt2V/f1vJrekPwATTY3TTlYG2DH0VwzY+0+iKwuauD5Adxjzd0pKSoiLi4N84Ou1EH0x50T+p/H5laXUvP8zClc8S6eiXYTXVNTfX12B2bOMok5D6RjegYjqU828vnsC+e83kGMLJLlF5XSP11t8SoUqbyRT2UCeMeYkcFJEPgdOBxolU8aYl4CXAMaOHWtqi5KxmnU5Pg80gRxfIMcGLuLr8oTTkaeYy54gfZT92HTgYQBigGG2P4DVF8pJHytJ6M2wmXMga4gb128ivgwn9VRAmKmic3xHKKhwul8QEu5f03jkyrY3ZuK9pJ+b7vRcVwL57zeQYwskR4vLOD010d9hKKV8xBsd0D8AzhORCBHpAJwF7PDCdVUoa64De3NcdWB3bCrqyfVddoDvDbcvs123ifMavn5cMkR2gNXPQd4+92JQIcEYU7vIsVIqNLnTGuFtrCGCriKSjTVUEAlgjHnRGLNDRD4GsoAa4BVjzFZX11Oqlpf6WLWqqWhzmusA39x+Z69/dBu8fiX8ayrc+j/oOqh1sdlp64WgUFRWRVlljXY/V8HJz58zcXFxlJSUuNw/a9Ysli5dytSpU7niiiv45S9/SVZWFu+88w7XXONGc2gvcWc23/VuHPMU8JRXIlLKXZ4kS+5cG1x/iLiTzDWUPNxKol6/wpoxeM5dsPblZmcLOl3uxt+tF3QpHrfZu59rjykVdPz9OeOGl156ifz8fMLDwzl48CCvvfYaf/rTn9o8Dp2nq5QrzSVrrUnmug+FW/4Hr/wAPnUYxXI2W3DxPVDlsNzNop9D5n8gPBL2Z0BNg8U9W9J6wZPfNnUpnhap636ut/lUgPloNny/xfX+7HVQXV5/W2UpfHA3bHjd+Tk9RsKl81xecvbs2fTu3bt2CZdHHnmEiIgIVq5cyYkTJ6isrOSxxx5j2rRpzYZ/5ZVXUlJSwplnnsmDDz7IzJkzAQgL80YFU8u0/Ssq1d51HwJRHRtvryyF9++EP/SDhf8Pqhr0qaqphINfwMnjjRMpu8JsMMZKeJ4ZAY8kWl+z5tcdY0+GCg8Dpi4ZaniMs/NP5Tvv4WVP5FQ9izJz+MXbGwG4551MFmW6aJmhVCBqmEg1t90NM2fOZP78us+a+fPnc8stt/D++++zceNGVq5cya9+9SuMaaaBM7B48WJiY2PZtGlTbSLlLzoypZQ/uFrOxlTDiKth3Ssu9hv46SorwXEymxEM/PV0KP6ucUNTsEaOls91ngwt+z/oMgD2rYAvnoKq8rrz378Tlj0EJxu3s6ilPbTqWZSZw4MLt1BaafVDO1pUzoMLrVEAby4cq1SrNTGCBLj+nEnoDbctadVLjhkzhtzcXI4cOcKxY8fo3LkzPXr04L777uPzzz8nLCyMnJwcjh49So8ePVr1Gv6gI1NK+UNTswUv+3PzswVdzWYcc7PVOb66QeuGylLrtuE/JrpIwoCTufDKRbDysbpEys5UQ3kJTHoYOnZr2ffURkRkiojsEpG9IjLbyf4LRGSjiFSJyDUN9t0iIntsf27xRjxPLdtVm0jZlVZW89SyXd64vFK+19ys6Va69tprWbBgAe+++y4zZ87kzTff5NixY2zYsIFNmzaRnJxMWVmZR6/R1jSZUsofmvuQam3rh2l/h5oa569ZVQodkpzfYgTo0BVumO98H1hL9Zx/v9WF3gcfsJ4QkXDgOeBSrHZk14vIsAaHHQJuBd5qcG4XrFnKZwHjgYdFpLOnMR0paLicUdPblQo4nraYcWHmzJm88847LFiwgGuvvZbCwkK6d+9OZGQkK1eu5Ntvv/VO/G1Ib/Mp5Q8tmC1Yb7kbd1o/JDhvaEpCb7h5ofOGopGxMOVJOG2ydZzT8x16aDUXW9sbD+w1xuwHEJF3gGnAdvsBxpiDtn0Ns83JwKfGmHzb/k+BKcDbngTUKzGWHCeJU6/EWCdHKxWgfDBrevjw4RQXF5OSkkLPnj258cYbueKKKxg5ciRjx45lyJAhrbruunXr+OEPf8iJEyf48MMPefjhh9m2bZtXY3dFkyml/MXN2YKrWtplvLkeWM0lci3oodXi2HwnBXDMALOxRppae67HRU2zJg+uVzMFEBsZzqzJgz29tFJBb8uWulmEXbt2ZfXq1U6Pa6rHVMP948aNIzvbP7WbmkwpFWo8bWjamh5a7YSr9UWdrVGYCNw8NJz3dteQV2ZIihGuPi2cxMI9ZGTsadO4A30NxUCOL5Bjg5bHl5CQQHFxse8CaqC6urpNX6+lXMVXVlbWovdVkymlQpGnQ/O+bIjqGzmAY9V+qm2bu+emNzg3w9mBrtYXdbVGYTrwkJtB+FKgr6EYyPEFcmzQ8vh27NhBfHy87wJqoLi42OPX27JlCzfffHO9bdHR0XzzzTceXRdcxxcTE8OYMWPcvo4mU0qpULAOGCQiaVjJ0XXADW6euwx4wqHo/BLgQe+HqJRqjZEjR7Jp0yZ/h9Eknc2nlAp6xpgq4G6sxGgHMN8Ys01E5orIlQAiMs62vui1wD9EZJvt3HzgUayEbB0w116MrlQocqchZnvWmvdHR6aUUiHBGLMUWNpg2xyHx+uwbuE5O/dV4FWfBqhUAIiJiSEvL4+kpCRExN/hBBxjDHl5ecTEtGwtTU2mlFJKqXYiNTWV7Oxsjh1rYjUDLyorK2txYtKWnMUXExNDamrLmhBrMqWUUkq1E5GRkaSlpbXZ62VkZLSokLuteSs+rZlSSimllPKAJlNKKaWUUh7QZEoppZRSygPirymSInIMcFzNsCtw3C/BuCeQ4wvk2EDj81Qgx9fS2PoaY7r5Kpi21OAzLJD/jkDj80QgxwYan6daEp/Lzy+/JVMNich6Y8xYf8fhSiDHF8ixgcbnqUCOL5Bja0uB/j5ofK0XyLGBxucpb8Wnt/mUUkoppTygyZRSSimllAcCKZl6yd8BNCOQ4wvk2EDj81QgxxfIsbWlQH8fNL7WC+TYQOPzlFfiC5iaKaWUUkqpYBRII1NKKaWUUkHH78mUiEwRkV0isldEZvs7noZE5KCIbBGRTSKyPgDieVVEckVkq8O2LiLyqYjssX3tHGDxPSIiObb3cJOITPVTbL1FZKWIbBeRbSJyr217QLx/TcQXKO9fjIisFZHNtvh+b9ueJiLf2H6G3xWRKH/E5y/6GdaiWPTzy7P4AvYzrN1/fhlj/PYHCAf2Af2BKGAzMMyfMTmJ8SDQ1d9xOMRzAXAGsNVh2x+B2bbHs4E/BFh8jwAPBMB71xM4w/Y4HtgNDAuU96+J+ALl/RMgzvY4EvgGOBuYD1xn2/4i8DN/x9qG74l+hrUsFv388iy+gP0Ma++fX/4emRoP7DXG7DfGVADvANP8HFNAM8Z8DuQ32DwNeN32+HVgelvG5MhFfAHBGPOdMWaj7XExsANIIUDevybiCwjGUmJ7Gmn7Y4CLgAW27X799+cH+hnWAvr55ZlA/gxr759f/k6mUoDDDs+zCaA338YAn4jIBhG5w9/BuJBsjPnO9vh7INmfwbhwt4hk2YbR/TaMbyci/YAxWL+dBNz71yA+CJD3T0TCRWQTkAt8ijUqU2CMqbIdEog/w76kn2GeC7ifPycC4ufPUSB/hrXHzy9/J1PB4DxjzBnApcBdInKBvwNqirHGKgNtiuYLwABgNPAd8Gd/BiMiccB7wC+NMUWO+wLh/XMSX8C8f8aYamPMaCAVa1RmiL9iUW4Lms+wQPj5cyJgfv7sAvkzrL1+fvk7mcoBejs8T7VtCxjGmBzb11zgfay/gEBzVER6Ati+5vo5nnqMMUdt/4hrgJfx43soIpFYP+hvGmMW2jYHzPvnLL5Aev/sjDEFwErgHCBRRCJsuwLuZ9jH9DPMcwHz8+dMoP38BfJnWHv+/PJ3MrUOGGSrpo8CrgMW+zmmWiLSUUTi7Y+BS4CtTZ/lF4uBW2yPbwE+8GMsjdh/yG1+iJ/eQxER4J/ADmPM0w67AuL9cxVfAL1/3UQk0fY4FrgYqy5iJXCN7bCA+/fnY/oZ5rmA+PlzJVB+/myxBOxnWLv//AqACvupWFX/+4D/83c8DWLrjzU7ZzOwLRDiA97GGiqtxLq/ezuQBCwH9gCfAV0CLL43gC1AFtYPfU8/xXYe1vB3FrDJ9mdqoLx/TcQXKO/fKCDTFsdWYI5te39gLbAX+C8Q7a9/f356X/QzzP149PPLs/gC9jOsvX9+aQd0pZRSSikP+Ps2n1JKKaVUUNNkSimllFLKA5pMKaWUUkp5QJMppZRSSikPaDKllFJKKeUBTaZUwBCRdBH5n7/jUEqpltLPr/ZNkymllFJKKQ9oMqVaTERuEpG1IrJJRP5hWzyyRESeEZFtIrJcRLrZjh0tImtsi1y+b1/kUkQGishnIrJZRDaKyADb5eNEZIGI7BSRN21ddRGReSKy3XadP/npW1dKBTn9/FK+oMmUahERGQrMBCYYa8HIauBGoCOw3hgzHFgFPGw75d/Ab4wxo7C64Nq3vwk8Z4w5HTgXq+swWCuN/xIYhtWZdoKIJGEtQzDcdp3HfPk9KqVCk35+KV/RZEq11CTgTGCdiGyyPe8P1ADv2o75D3CeiCQAicaYVbbtrwMX2NYKSzHGvA9gjCkzxpyyHbPWGJNtrEUxNwH9gEKgDPiniFwF2I9VSqmW0M8v5ROaTKmWEuB1Y8xo25/BxphHnBzX2nWKyh0eVwMRxpgqrJXGFwCXAx+38tpKqfZNP7+UT2gypVpqOXCNiHQHEJEuItIX69+SfeXtG4AvjTGFwAkROd+2/WZglTGmGMgWkem2a0SLSAdXLygicUCCMWYpcB9wug++L6VU6NPPL+UTEf4OQAUXY8x2Efkt8ImIhGGtrn4XcBIYb9uXi1WXAHAL8KLtw2Y/cJtt+83AP0Rkru0a1zbxsvHAByISg/Wb5f1e/raUUu2Afn4pXxFjWjuaqVQdESkxxsT5Ow6llGop/fxSntLbfEoppZRSHtCRKaWUUkopD+jIlFJKKaWUBzSZUkoppZTygCZTSimllFIe0GRKKaWUUsoDmkwppZRSSnlAkymllFJKKQ/8fwF3n9rSrQN4AAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"model.save_pretrained(\"model\")\nmodel2 = ElectraForMaskedLM.from_pretrained(\"model\")\npipe = pipeline(\"fill-mask\", model=model2,tokenizer=tokenizer)\npipe(\"Why don't you ask [MASK]?\")\n","metadata":{"id":"Kui0fvWMLsfx","execution":{"iopub.status.busy":"2022-03-30T01:49:27.434221Z","iopub.execute_input":"2022-03-30T01:49:27.434857Z","iopub.status.idle":"2022-03-30T01:49:28.231170Z","shell.execute_reply.started":"2022-03-30T01:49:27.434808Z","shell.execute_reply":"2022-03-30T01:49:28.230487Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at model were not used when initializing ElectraForMaskedLM: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n- This IS expected if you are initializing ElectraForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing ElectraForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of ElectraForMaskedLM were not initialized from the model checkpoint at model and are newly initialized: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_predictions.LayerNorm.bias', 'generator_predictions.dense.bias', 'generator_predictions.LayerNorm.weight', 'generator_lm_head.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.000390280649298802,\n  'token': 17029,\n  'token_str': 'p a r a l y m p i c',\n  'sequence': \"why don't you ask paralympic?\"},\n {'score': 0.00033108098432421684,\n  'token': 20887,\n  'token_str': 'u m p i r e',\n  'sequence': \"why don't you ask umpire?\"},\n {'score': 0.00031521200435236096,\n  'token': 11175,\n  'token_str': 's u t t o n',\n  'sequence': \"why don't you ask sutton?\"},\n {'score': 0.00031011170358397067,\n  'token': 27206,\n  'token_str': 'f o r b i d',\n  'sequence': \"why don't you ask forbid?\"},\n {'score': 0.00029877893393859267,\n  'token': 13522,\n  'token_str': 'k o l k a t a',\n  'sequence': \"why don't you ask kolkata?\"}]"},"metadata":{}}]},{"cell_type":"code","source":"pipe(\"What is [MASK]?\")\n","metadata":{"id":"tQvJkErmL5mc","execution":{"iopub.status.busy":"2022-03-30T01:49:28.235293Z","iopub.execute_input":"2022-03-30T01:49:28.237238Z","iopub.status.idle":"2022-03-30T01:49:28.272941Z","shell.execute_reply.started":"2022-03-30T01:49:28.237199Z","shell.execute_reply":"2022-03-30T01:49:28.272264Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.00041817454621195793,\n  'token': 13547,\n  'token_str': 'o w l',\n  'sequence': 'what is owl?'},\n {'score': 0.00032938283402472734,\n  'token': 6680,\n  'token_str': 'a s l e e p',\n  'sequence': 'what is asleep?'},\n {'score': 0.0003092053811997175,\n  'token': 18234,\n  'token_str': 'i m p a i r e d',\n  'sequence': 'what is impaired?'},\n {'score': 0.00030591472750529647,\n  'token': 13204,\n  'token_str': 'w h e e l c h a i r',\n  'sequence': 'what is wheelchair?'},\n {'score': 0.00028471663244999945,\n  'token': 22388,\n  'token_str': 'o w l s',\n  'sequence': 'what is owls?'}]"},"metadata":{}}]},{"cell_type":"code","source":"pipe(\"Let's talk about [MASK] physics\")","metadata":{"id":"zTLdiDnvL5vq","execution":{"iopub.status.busy":"2022-03-30T01:49:28.274385Z","iopub.execute_input":"2022-03-30T01:49:28.278165Z","iopub.status.idle":"2022-03-30T01:49:28.317354Z","shell.execute_reply.started":"2022-03-30T01:49:28.278092Z","shell.execute_reply":"2022-03-30T01:49:28.316683Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.00027219142066314816,\n  'token': 26593,\n  'token_str': 'l e t t e r m a n',\n  'sequence': \"let's talk about letterman physics\"},\n {'score': 0.00027064024470746517,\n  'token': 11267,\n  'token_str': 'b e n g a l i',\n  'sequence': \"let's talk about bengali physics\"},\n {'score': 0.000250261218752712,\n  'token': 0,\n  'token_str': '[ P A D ]',\n  'sequence': \"let's talk about physics\"},\n {'score': 0.0002445296267978847,\n  'token': 14920,\n  'token_str': 'd e n i a l',\n  'sequence': \"let's talk about denial physics\"},\n {'score': 0.00024003868747968227,\n  'token': 23070,\n  'token_str': '# # s k a y a',\n  'sequence': \"let's talk aboutskaya physics\"}]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"id":"QaWF9GveQr_w"},"execution_count":null,"outputs":[]}]}